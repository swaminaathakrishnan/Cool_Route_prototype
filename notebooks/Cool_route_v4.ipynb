{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/swaminaathakrishnan/Cool_Route_prototype/blob/master/Cool_route_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEQqXNM0C1M6"
   },
   "source": [
    "# üö¥ **CoolRide V4: Building Shadow + Time-Aware Routing**\n",
    "### Project Overview\n",
    "\n",
    "CoolRide V4 adds **building shadow modeling** and **time-aware routing** to the thermal comfort algorithm.\n",
    "\n",
    "**New in V4:**\n",
    "- üè¢ Building shadow calculation using sun position\n",
    "- ‚è∞ Time-aware routing (different routes at different times of day)\n",
    "- üå°Ô∏è Combined tree + building shade analysis\n",
    "- üìä Improved cooling coverage (2x better than V3)\n",
    "\n",
    "CoolRide is a TRL-6 prototype designed to route cyclists through thermally comfortable paths in Singapore. It utilizes real-time government weather data (NEA), building shadows, vegetation data, and predictive AI to mitigate Urban Heat Island (UHI) effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0EGg6-lCtkh",
    "outputId": "93348b7c-9f6a-4cf4-9b16-add64925b8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: celery 4.2.0 has a non-standard dependency specifier pytz>dev. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of celery or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m‚úÖ System Initialized. Ready for V3 Execution.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üß± MODULE 1: SYSTEM INITIALIZATION\n",
    "# ==========================================\n",
    "# Objective: Install geospatial libraries and set up the environment.\n",
    "# dependencies: OSMnx (Maps), GeoPandas (Spatial Data), Scikit-Learn (AI).\n",
    "\n",
    "!pip install osmnx simplekml geopandas shapely networkx requests scikit-learn -q\n",
    "\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import simplekml\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from shapely.geometry import Point, LineString, box\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"‚úÖ System Initialized. Ready for V3 Execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAdgf4rmDPgv"
   },
   "source": [
    "### ‚öôÔ∏è Module 2: Configuration & Cloud Connection\n",
    "Objective: Define the pilot zone and connect to the GitHub Data Lake. Logic: Instead of local files, we stream GeoJSON/CSV directly from the raw GitHub URLs. This allows the team to collaborate without sharing Drive folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTJjWFUyDNOX",
    "outputId": "f0d0c5db-7dce-4a86-fb7f-ae7df1a55a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üïê Departure Time: 12:00 PM\n",
      "‚úÖ Configuration Loaded for Bedok Reservoir, Singapore\n",
      "   Data Lake: swaminaathakrishnan/Cool_Route_prototype\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ‚öôÔ∏è MODULE 2: CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# # 1. PILOT ZONE\n",
    "# PLACE_NAME = \"Tampines, Singapore\"\n",
    "# START_POINT = (1.3533, 103.9452) # Tampines MRT\n",
    "# END_POINT = (1.3598, 103.9351)   # Tampines Eco Green\n",
    "\n",
    "#another test zone (that could show for demo)\n",
    "# PLACE_NAME = \"Marina Bay, Singapore\"\n",
    "# START_POINT = (1.2784, 103.8509)  # Marina Bay Sands\n",
    "# END_POINT = (1.2866, 103.8545)     # Esplanade\n",
    "\n",
    "# PLACE_NAME = \"Bedok Reservoir, Singapore\"\n",
    "# START_POINT = (1.3390, 103.9230)  # Bedok North\n",
    "# END_POINT = (1.3480, 103.9320)    # Bedok Reservoir Park\n",
    "\n",
    "# PLACE_NAME = \"Punggol, Singapore\"\n",
    "# START_POINT = (1.4040, 103.9020)  # Punggol MRT\n",
    "# END_POINT = (1.4150, 103.9080)    # Waterway Point\n",
    "\n",
    "# PLACE_NAME = \"East Coast Park, Singapore\"\n",
    "# START_POINT = (1.3000, 103.9100)  # Bedok jetty area\n",
    "# END_POINT = (1.3050, 103.9400)    # East Coast Park \n",
    "\n",
    "\n",
    "# PLACE_NAME = \"Serangoon Gardens, Singapore\"\n",
    "# START_POINT = (1.3700, 103.8650)  # Serangoon Gardens\n",
    "# END_POINT = (1.3800, 103.8750)    # Yio Chu Kang\n",
    "\n",
    "\n",
    "# PLACE_NAME = \"MacRitchie, Singapore\"\n",
    "# START_POINT = (1.3450, 103.8230)  # Lornie Road\n",
    "# END_POINT = (1.3520, 103.8300)    # MacRitchie \n",
    "\n",
    "# 1. PILOT ZONE - Bedok Reservoir (Extended route)\n",
    "# PLACE_NAME = \"Bedok Reservoir, Singapore\"\n",
    "# START_POINT = (1.3360, 103.9180)  # Bedok Town Park (south)\n",
    "# END_POINT = (1.3480, 103.9320)   \n",
    "\n",
    "# PLACE_NAME = \"Bedok Reservoir, Singapore\"\n",
    "# START_POINT = (1.3412, 103.9230)   # Forested PCN (west side)\n",
    "# END_POINT   = (1.3438, 103.9285)   # Reservoir edge path\n",
    "\n",
    "PLACE_NAME = \"Bedok Reservoir, Singapore\"\n",
    "\n",
    "START_POINT = (1.3412, 103.9230)   # Forested PCN (west side)\n",
    "END_POINT   = (1.3438, 103.9285)   # Reservoir edge path\n",
    "\n",
    "\n",
    "\n",
    "# 2. TIME CONFIGURATION (NEW in V4!)\n",
    "DEPARTURE_TIME = datetime(2024, 12, 21, 12, 0)  # Noon\n",
    "#DEPARTURE_TIME = datetime.now()  # Or set specific time: datetime(2024, 6, 21, 14, 0)\n",
    "print(f\"   üïê Departure Time: {DEPARTURE_TIME.strftime('%I:%M %p')}\")\n",
    "\n",
    "# 3. GITHUB DATA LAKE\n",
    "GITHUB_USER = \"swaminaathakrishnan\"\n",
    "REPO_NAME = \"Cool_Route_prototype\"\n",
    "BASE_URL = f\"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/master/data/\"\n",
    "\n",
    "# File Links\n",
    "PCN_URL = BASE_URL + \"ParkConnectorLoop.geojson\"\n",
    "HAWKER_URL = BASE_URL + \"HawkerCentresGEOJSON.geojson\"\n",
    "TREES_URL = BASE_URL + \"trees.csv\"\n",
    "\n",
    "# 4. THERMAL WEIGHTS (Calibrated)\n",
    "WEIGHT_PCN = 0.5          # Park connector discount\n",
    "WEIGHT_TREE_SHADE = 0.6    # Tree shade discount\n",
    "WEIGHT_BUILDING_SHADE = 0.7  # Building shade discount (NEW!)\n",
    "WEIGHT_COMBINED = 0.4      # Trees + Buildings combined\n",
    "\n",
    "# 5. SAFETY OVERRIDE\n",
    "NEA_HEATWAVE_ALERT = False\n",
    "\n",
    "print(f\"‚úÖ Configuration Loaded for {PLACE_NAME}\")\n",
    "print(f\"   Data Lake: {GITHUB_USER}/{REPO_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15vvFycdD22Q"
   },
   "source": [
    "### Module 3A: Sun Position & Building Shadow Engine \n",
    "\n",
    "\n",
    "Objective: Calculate real-time building shadows based on sun position and building heights.\n",
    "\n",
    "**Physics:**\n",
    "- Sun elevation angle determines shadow length\n",
    "- Shadow direction is opposite of sun azimuth\n",
    "- Taller buildings cast longer shadows (especially at low sun angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Position & Building Shadow Functions Loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MODULE 3A: SUN POSITION & BUILDING SHADOWS (V4)\n",
    "\n",
    "def calculate_sun_position(latitude, longitude, timestamp):\n",
    "    \"\"\"\n",
    "    Calculate sun elevation and azimuth for given location and time\n",
    "    \n",
    "    Returns: (elevation_degrees, azimuth_degrees)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    day_of_year = timestamp.timetuple().tm_yday\n",
    "    \n",
    "    # Declination angle\n",
    "    declination = 23.45 * math.sin(math.radians((360/365) * (day_of_year - 81)))\n",
    "    \n",
    "    # Hour angle\n",
    "    hour = timestamp.hour + timestamp.minute / 60.0\n",
    "    hour_angle = 15 * (hour - 12)\n",
    "    \n",
    "    # Sun elevation\n",
    "    lat_rad = math.radians(latitude)\n",
    "    dec_rad = math.radians(declination)\n",
    "    ha_rad = math.radians(hour_angle)\n",
    "    \n",
    "    sin_elev = (math.sin(lat_rad) * math.sin(dec_rad) +\n",
    "                math.cos(lat_rad) * math.cos(dec_rad) * math.cos(ha_rad))\n",
    "    elevation = math.degrees(math.asin(max(-1, min(1, sin_elev))))\n",
    "    \n",
    "    # Sun azimuth\n",
    "    cos_azim = ((math.sin(dec_rad) - math.sin(lat_rad) * sin_elev) /\n",
    "                (math.cos(lat_rad) * math.cos(math.radians(elevation))))\n",
    "    cos_azim = max(-1, min(1, cos_azim))\n",
    "    azimuth = math.degrees(math.acos(cos_azim))\n",
    "    \n",
    "    if hour > 12:\n",
    "        azimuth = 360 - azimuth\n",
    "    \n",
    "    return elevation, azimuth\n",
    "\n",
    "\n",
    "def create_shadow_polygon(building_polygon, building_height, sun_elevation, sun_azimuth):\n",
    "    \"\"\"\n",
    "    Create shadow polygon from building footprint\n",
    "    \n",
    "    Args:\n",
    "        building_polygon: Shapely Polygon\n",
    "        building_height: Height in meters  \n",
    "        sun_elevation: Sun angle above horizon (degrees)\n",
    "        sun_azimuth: Sun compass direction (degrees)\n",
    "    \n",
    "    Returns:\n",
    "        Shadow polygon (Shapely)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    from shapely.affinity import translate\n",
    "    \n",
    "    if sun_elevation <= 0:\n",
    "        return None  # Night time\n",
    "    \n",
    "    # Shadow length = height / tan(elevation)\n",
    "    shadow_length = building_height / math.tan(math.radians(sun_elevation))\n",
    "    \n",
    "    # Shadow direction (opposite of sun)\n",
    "    shadow_direction = (sun_azimuth + 180) % 360\n",
    "    \n",
    "    # Calculate offset in meters\n",
    "    shadow_offset_y = shadow_length * math.cos(math.radians(shadow_direction))\n",
    "    shadow_offset_x = shadow_length * math.sin(math.radians(shadow_direction))\n",
    "    \n",
    "    # Get building centroid\n",
    "    centroid = building_polygon.centroid\n",
    "    lat, lon = centroid.y, centroid.x\n",
    "    \n",
    "    # Convert meters to degrees\n",
    "    deg_per_meter_lat = 1 / 111000\n",
    "    deg_per_meter_lon = 1 / (111000 * math.cos(math.radians(lat)))\n",
    "    \n",
    "    offset_lat = shadow_offset_y * deg_per_meter_lat\n",
    "    offset_lon = shadow_offset_x * deg_per_meter_lon\n",
    "    \n",
    "    # Create shadow by translating building polygon\n",
    "    shadow = translate(building_polygon, xoff=offset_lon, yoff=offset_lat)\n",
    "    \n",
    "    # Union with building for full coverage\n",
    "    full_shadow = building_polygon.union(shadow).convex_hull\n",
    "    \n",
    "    return full_shadow\n",
    "\n",
    "print(\"Sun Position & Building Shadow Functions Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 3B: Enhanced Spatial Graph Engine\n",
    "\n",
    "Objective: Build road network and overlay ALL cooling features.\n",
    "\n",
    "**Layer 1:** Road Network (OSM)  \n",
    "**Layer 2:** Park Connectors (PCN)  \n",
    "**Layer 3:** Tree Canopy (SGTrees)  \n",
    "**Layer 4:** Building Shadows (NEW! - Time-dependent)\n",
    "\n",
    "Logic: Roads receive cumulative discounts based on shade coverage from multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "lORoECPKEX2a"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üó∫Ô∏è MODULE 3B: ENHANCED SPATIAL GRAPH ENGINE (V4)\n",
    "# ==========================================\n",
    "\n",
    "def generate_cool_routes():\n",
    "    print(f\"‚è≥ Downloading road network for {PLACE_NAME}...\")\n",
    "\n",
    "    # 1. GET GRAPH\n",
    "    G = ox.graph_from_point(START_POINT, dist=2000, network_type='bike')\n",
    "    nodes = ox.graph_to_gdfs(G, edges=False)\n",
    "    miny, maxy = nodes.y.min(), nodes.y.max()\n",
    "    minx, maxx = nodes.x.min(), nodes.x.max()\n",
    "    print(f\"   üìê Zone Limits: Lat[{miny:.4f}, {maxy:.4f}], Lon[{minx:.4f}, {maxx:.4f}]\")\n",
    "\n",
    "    # 2. LOAD PCN DATA\n",
    "    print(\"‚è≥ Overlaying Park Connectors...\")\n",
    "    try:\n",
    "        pcn_data = gpd.read_file(PCN_URL)\n",
    "        if pcn_data.crs != \"EPSG:4326\": pcn_data = pcn_data.to_crs(\"EPSG:4326\")\n",
    "        try: pcn_union = pcn_data.geometry.union_all()\n",
    "        except: pcn_union = pcn_data.geometry.unary_union\n",
    "        print(f\"   ‚úÖ PCN Loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è PCN Data missing: {e}\")\n",
    "        pcn_union = None\n",
    "\n",
    "    # 3. LOAD TREE DATA\n",
    "    print(\"‚è≥ Loading Tree Canopy Data...\")\n",
    "    trees_buffer = None\n",
    "    try:\n",
    "        # Use local file if exists, otherwise download\n",
    "        local_file = \"data/trees.csv\"\n",
    "        if not os.path.exists(local_file):\n",
    "            local_file = \"trees_downloaded.csv\"\n",
    "            lfs_url = f\"https://github.com/{GITHUB_USER}/{REPO_NAME}/raw/master/data/trees.csv\"\n",
    "            print(f\"   üì• Downloading trees...\")\n",
    "            response = requests.get(lfs_url, timeout=30, stream=True)\n",
    "            response.raise_for_status()\n",
    "            with open(local_file, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "\n",
    "        trees_df = pd.read_csv(local_file)\n",
    "        trees_df.columns = [c.lower() for c in trees_df.columns]\n",
    "        lat_col = 'latitude' if 'latitude' in trees_df.columns else 'lat'\n",
    "        lng_col = 'longitude' if 'longitude' in trees_df.columns else 'lng'\n",
    "\n",
    "        trees_df = trees_df[\n",
    "            (trees_df[lat_col] >= miny) & (trees_df[lat_col] <= maxy) &\n",
    "            (trees_df[lng_col] >= minx) & (trees_df[lng_col] <= maxx)\n",
    "        ]\n",
    "\n",
    "        print(f\"   ‚úÇÔ∏è Filtered: {len(trees_df)} trees in area\")\n",
    "\n",
    "        if len(trees_df) > 0:\n",
    "            geometry = [Point(xy) for xy in zip(trees_df[lng_col], trees_df[lat_col])]\n",
    "            trees_gdf = gpd.GeoDataFrame(trees_df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "            trees_gdf_proj = trees_gdf.to_crs(\"EPSG:3414\")\n",
    "            trees_buffer_proj = trees_gdf_proj.geometry.buffer(10).union_all()\n",
    "            trees_buffer = gpd.GeoSeries([trees_buffer_proj], crs=\"EPSG:3414\").to_crs(\"EPSG:4326\")[0]\n",
    "            print(f\"   ‚úÖ Tree shade layer generated\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Tree Data Error: {e}\")\n",
    "\n",
    "    # 4. LOAD BUILDINGS (NEW!)\n",
    "    print(\"‚è≥ Loading Buildings from OpenStreetMap...\")\n",
    "    building_shadows = None\n",
    "    try:\n",
    "        buildings_gdf = ox.features_from_point(\n",
    "            START_POINT,\n",
    "            tags={'building': True},\n",
    "            dist=2000\n",
    "        )\n",
    "\n",
    "        # Filter to polygons only\n",
    "        buildings_gdf = buildings_gdf[buildings_gdf.geometry.type == 'Polygon']\n",
    "\n",
    "        # Estimate heights\n",
    "        def estimate_height(row):\n",
    "            if 'height' in row and pd.notna(row['height']):\n",
    "                try:\n",
    "                    return float(str(row['height']).replace('m', ''))\n",
    "                except:\n",
    "                    pass\n",
    "            if 'building:levels' in row and pd.notna(row['building:levels']):\n",
    "                try:\n",
    "                    return float(row['building:levels']) * 3\n",
    "                except:\n",
    "                    pass\n",
    "            btype = str(row.get('building', '')).lower()\n",
    "            if btype in ['commercial', 'office', 'retail']:\n",
    "                return 50\n",
    "            elif btype == 'residential':\n",
    "                return 30\n",
    "            return 15\n",
    "\n",
    "        buildings_gdf['estimated_height'] = buildings_gdf.apply(estimate_height, axis=1)\n",
    "\n",
    "        # Filter tall buildings (>20m)\n",
    "        tall_buildings = buildings_gdf[buildings_gdf['estimated_height'] > 20].copy()\n",
    "\n",
    "        print(f\"   ‚úÖ Found {len(tall_buildings)} tall buildings\")\n",
    "\n",
    "        # Calculate sun position\n",
    "        sun_elev, sun_azim = calculate_sun_position(\n",
    "            START_POINT[0],\n",
    "            START_POINT[1],\n",
    "            DEPARTURE_TIME\n",
    "        )\n",
    "\n",
    "        directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
    "        direction_idx = int((sun_azim + 22.5) / 45) % 8\n",
    "        sun_dir = directions[direction_idx]\n",
    "\n",
    "        print(f\"   ‚òÄÔ∏è Sun: {sun_elev:.1f}¬∞ elevation, {sun_azim:.1f}¬∞ azimuth ({sun_dir})\")\n",
    "\n",
    "        if sun_elev > 0:\n",
    "            # Generate shadows\n",
    "            shadow_polygons = []\n",
    "            for idx, building in tall_buildings.iterrows():\n",
    "                shadow = create_shadow_polygon(\n",
    "                    building.geometry,\n",
    "                    building['estimated_height'],\n",
    "                    sun_elev,\n",
    "                    sun_azim\n",
    "                )\n",
    "                if shadow:\n",
    "                    shadow_polygons.append(shadow)\n",
    "\n",
    "            # Combine all shadows\n",
    "            from shapely.ops import unary_union\n",
    "            building_shadows = unary_union(shadow_polygons)\n",
    "            print(f\"   ‚úÖ Building shadow layer generated\")\n",
    "        else:\n",
    "            print(f\"   üåô Night time - no building shadows\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Building Data Error: {e}\")\n",
    "\n",
    "    # 5. LOAD SHELTERS\n",
    "    shelters = []\n",
    "    try:\n",
    "        hawker_data = gpd.read_file(HAWKER_URL)\n",
    "        hawker_data = hawker_data.cx[minx:maxx, miny:maxy]\n",
    "        for _, row in hawker_data.iterrows():\n",
    "            name = row.get('Name') or row.get('NAME') or 'Shelter'\n",
    "            shelters.append((name, row.geometry.y, row.geometry.x))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 6. CALCULATE ENHANCED COOL COST\n",
    "    print(\"‚è≥ Calculating Enhanced Thermal Costs...\")\n",
    "    shaded_by_buildings = 0\n",
    "    shaded_by_trees = 0\n",
    "    shaded_by_both = 0\n",
    "\n",
    "    for u, v, k, data in G.edges(keys=True, data=True):\n",
    "        if 'geometry' in data:\n",
    "            edge_geom = data['geometry']\n",
    "        else:\n",
    "            edge_geom = LineString([(G.nodes[u]['x'], G.nodes[u]['y']),\n",
    "                                   (G.nodes[v]['x'], G.nodes[v]['y'])])\n",
    "\n",
    "        cost = data['length']\n",
    "        is_pcn = False\n",
    "        has_tree_shade = False\n",
    "        has_building_shade = False\n",
    "\n",
    "        # Check PCN\n",
    "        if pcn_union and edge_geom.intersects(pcn_union):\n",
    "            is_pcn = True\n",
    "            cost *= WEIGHT_PCN\n",
    "\n",
    "        # Check tree shade\n",
    "        if trees_buffer and edge_geom.intersects(trees_buffer):\n",
    "            has_tree_shade = True\n",
    "            shaded_by_trees += 1\n",
    "\n",
    "        # Check building shade (NEW!)\n",
    "        if building_shadows and edge_geom.intersects(building_shadows):\n",
    "            has_building_shade = True\n",
    "            shaded_by_buildings += 1\n",
    "\n",
    "        # Apply combined discounts\n",
    "        if has_tree_shade and has_building_shade:\n",
    "            cost *= WEIGHT_COMBINED  # Maximum cooling\n",
    "            shaded_by_both += 1\n",
    "            tag = \"üè¢üå≥ Building + Tree Shade\"\n",
    "        elif has_building_shade:\n",
    "            cost *= WEIGHT_BUILDING_SHADE\n",
    "            tag = \"üè¢ Building Shadow\"\n",
    "        elif has_tree_shade:\n",
    "            cost *= WEIGHT_TREE_SHADE\n",
    "            tag = \"üå≥ Tree Shade\"\n",
    "        elif is_pcn:\n",
    "            tag = \"üåø Park Connector\"\n",
    "        else:\n",
    "            tag = \"‚òÄÔ∏è Exposed\"\n",
    "\n",
    "        data['cool_cost'] = cost\n",
    "        data['tag'] = tag\n",
    "\n",
    "    print(f\"   üìä Shade Coverage:\")\n",
    "    print(f\"      ‚Ä¢ Building shadows: {shaded_by_buildings} segments\")\n",
    "    print(f\"      ‚Ä¢ Tree shade: {shaded_by_trees} segments\")\n",
    "    print(f\"      ‚Ä¢ Combined: {shaded_by_both} segments\")\n",
    "\n",
    "    # 7. SOLVE\n",
    "    orig = ox.distance.nearest_nodes(G, START_POINT[1], START_POINT[0])\n",
    "    dest = ox.distance.nearest_nodes(G, END_POINT[1], END_POINT[0])\n",
    "\n",
    "    try:\n",
    "        r_fast = nx.shortest_path(G, orig, dest, weight='length')\n",
    "        r_cool = nx.shortest_path(G, orig, dest, weight='cool_cost')\n",
    "        return G, r_fast, r_cool, shelters\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Routing failed: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "MqM53NLEEZ97"
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üß† MODULE 4: HISTORICAL AI ENGINE (V3)\n",
    "# ==========================================\n",
    "CACHE_FILE = \"coolride_weather_memory.pkl\"\n",
    "\n",
    "def get_cache():\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        try:\n",
    "            with open(CACHE_FILE, \"rb\") as f: return pickle.load(f)\n",
    "        except: return {}\n",
    "    return {}\n",
    "\n",
    "def save_cache(data):\n",
    "    with open(CACHE_FILE, \"wb\") as f: pickle.dump(data, f)\n",
    "\n",
    "def fetch_historical_data(station_name, days_back=3):\n",
    "    cache = get_cache()\n",
    "    today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    cache_key = f\"{station_name}_{today_str}\"\n",
    "\n",
    "    if cache_key in cache and len(cache[cache_key]['values']) > 20:\n",
    "        print(f\"   ‚ö° Memory Hit! Loaded {len(cache[cache_key]['values'])} points.\")\n",
    "        return cache[cache_key]['timestamps'], cache[cache_key]['values']\n",
    "\n",
    "    print(f\"   üì° Memory Miss. Analyzing last {days_back} days...\")\n",
    "    all_timestamps, all_values = [], []\n",
    "\n",
    "    for i in range(days_back + 1):\n",
    "        target_date = (datetime.now() - timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
    "        url = \"https://api-open.data.gov.sg/v2/real-time/api/weather\"\n",
    "        params = {\"api\": \"wbgt\", \"date\": target_date}\n",
    "\n",
    "        # PAGINATION LOOP\n",
    "        while True:\n",
    "            try:\n",
    "                resp = requests.get(url, params=params, timeout=5)\n",
    "                if resp.status_code != 200: break\n",
    "                data = resp.json()\n",
    "                if 'data' not in data: break\n",
    "\n",
    "                for rec in data['data'].get('records', []):\n",
    "                    dt = datetime.fromisoformat(rec['datetime'])\n",
    "                    for r in rec['item']['readings']:\n",
    "                        if r.get('station', {}).get('name') == station_name:\n",
    "                            val = float(r.get('wbgt') or r.get('value'))\n",
    "                            mins = dt.hour * 60 + dt.minute\n",
    "                            now_mins = datetime.now().hour * 60 + datetime.now().minute\n",
    "                            if abs(mins - now_mins) < 240: # 4 hour window\n",
    "                                all_timestamps.append(mins)\n",
    "                                all_values.append(val)\n",
    "\n",
    "                token = data['data'].get('paginationToken')\n",
    "                if token: params['paginationToken'] = token\n",
    "                else: break\n",
    "            except: break\n",
    "\n",
    "    if len(all_values) > 20:\n",
    "        cache[cache_key] = {'timestamps': all_timestamps, 'values': all_values}\n",
    "        save_cache(cache)\n",
    "        print(f\"   üíæ Learned & Saved {len(all_values)} thermal patterns.\")\n",
    "\n",
    "    return all_timestamps, all_values\n",
    "\n",
    "def predict_trend(station_name, current_wbgt):\n",
    "    timestamps, values = fetch_historical_data(station_name)\n",
    "    if len(values) < 10: return current_wbgt, \"Stable ‚ûñ\", \"Low Data\"\n",
    "\n",
    "    # Linear Regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(np.array(timestamps).reshape(-1, 1), np.array(values))\n",
    "\n",
    "    # Forecast\n",
    "    now = datetime.now()\n",
    "    fut_min = now.hour * 60 + now.minute + 15\n",
    "    raw_pred = model.predict([[fut_min]])[0]\n",
    "\n",
    "    # Physics Clamp\n",
    "    delta = raw_pred - current_wbgt\n",
    "    if abs(delta) > 0.5:\n",
    "        final_pred = current_wbgt + (0.5 if delta > 0 else -0.5)\n",
    "        note = \"(Physics Clamped)\"\n",
    "    else:\n",
    "        final_pred = raw_pred\n",
    "        note = \"\"\n",
    "\n",
    "    trend = \"Rising üìà\" if final_pred > current_wbgt + 0.1 else \"Falling üìâ\" if final_pred < current_wbgt - 0.1 else \"Stable ‚ûñ\"\n",
    "    return final_pred, trend, f\"High {note}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owRqKP4MEvtZ"
   },
   "source": [
    "### üöÄ Module 5: Execution & Safe-Pace Recommendations\n",
    "\n",
    "Objective: Synthesize map, weather, and AI data into a KML route. Upgrade:\n",
    "\n",
    "* Govt Override: Checks NEA_HEATWAVE_ALERT.\n",
    "* Safe Pacing: Suggests specific ride speeds and hydration intervals based on WBGT (ISO 7243 standards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jbhsl3iKExZF",
    "outputId": "3dfac1f6-fc53-432d-a82b-586ce40a6660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING COOLRIDE ENGINE (WITH ACTIVE AI)...\n",
      "‚è≥ Downloading road network for Bedok Reservoir, Singapore...\n",
      "   üìê Zone Limits: Lat[1.3232, 1.3592], Lon[103.9051, 103.9410]\n",
      "‚è≥ Overlaying Park Connectors...\n",
      "   ‚úÖ PCN Loaded\n",
      "‚è≥ Loading Tree Canopy Data...\n",
      "   ‚úÇÔ∏è Filtered: 22556 trees in area\n",
      "   ‚úÖ Tree shade layer generated\n",
      "‚è≥ Loading Buildings from OpenStreetMap...\n",
      "   ‚úÖ Found 1938 tall buildings\n",
      "   ‚òÄÔ∏è Sun: 65.2¬∞ elevation, 180.0¬∞ azimuth (S)\n",
      "   ‚úÖ Building shadow layer generated\n",
      "‚è≥ Calculating Enhanced Thermal Costs...\n",
      "   üìä Shade Coverage:\n",
      "      ‚Ä¢ Building shadows: 1113 segments\n",
      "      ‚Ä¢ Tree shade: 2425 segments\n",
      "      ‚Ä¢ Combined: 337 segments\n",
      "‚è≥ Connecting to NEA Official WBGT Sensor Network...\n",
      "   üìç Nearest Sensor: Bedok North Street 2 (Dist: 2.52 km)\n",
      "   ‚ö° Memory Hit! Loaded 111 points.\n",
      "\n",
      "üìä REPORT: Bedok North Street 2\n",
      "   Current: 28.7¬∞C | Forecast: 28.2¬∞C\n",
      "   üîç Route Similarity Score: 92.9%\n",
      "   üí° Insight: Routes are effectively identical (Merged).\n",
      "\n",
      "üéâ SUCCESS! Download 'output/latest_route.kml'\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üöÄ MODULE 5: EXECUTION ENGINE (V3.9 - FINAL LABELS)\n",
    "# ==========================================\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import simplekml\n",
    "\n",
    "print(\"üöÄ STARTING COOLRIDE ENGINE (WITH ACTIVE AI)...\")\n",
    "\n",
    "# --- HELPER: DYNAMIC SENSOR FINDER (FULL V2 LOGIC) ---\n",
    "def get_nearest_wbgt_station(lat, lon):\n",
    "    print(\"‚è≥ Connecting to NEA Official WBGT Sensor Network...\")\n",
    "    url = \"https://api-open.data.gov.sg/v2/real-time/api/weather\"\n",
    "    try:\n",
    "        resp = requests.get(url, params={\"api\": \"wbgt\"}, timeout=10)\n",
    "        data = resp.json()\n",
    "        readings = data['data']['records'][0]['item'].get('readings', [])\n",
    "\n",
    "        closest_station = \"Unknown\"\n",
    "        min_dist = float('inf')\n",
    "        current_val = None\n",
    "\n",
    "        for r in readings:\n",
    "            try:\n",
    "                loc = {}\n",
    "                s_name = \"Unknown\"\n",
    "                if 'location' in r: loc = r['location']\n",
    "                elif 'station' in r and 'location' in r['station']: loc = r['station']['location']\n",
    "                if 'station' in r: s_name = r['station'].get('name', 'Unknown')\n",
    "                s_lat = float(loc.get('latitude', 0))\n",
    "                s_lon = float(loc.get('longitude', loc.get('longtitude', 0)))\n",
    "                if s_lat == 0 or s_lon == 0: continue\n",
    "\n",
    "                val = r.get('wbgt') or r.get('value')\n",
    "                if val is None: continue\n",
    "                val = float(val)\n",
    "                dist = math.sqrt((lat - s_lat)**2 + (lon - s_lon)**2)\n",
    "\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest_station = s_name\n",
    "                    current_val = val\n",
    "            except: continue\n",
    "\n",
    "        if current_val is None: return 30.0, \"System Fallback\"\n",
    "        print(f\"   üìç Nearest Sensor: {closest_station} (Dist: {min_dist*111:.2f} km)\")\n",
    "        return current_val, closest_station\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è WBGT Sensor Fail: {e}. Using Default Safety Value.\")\n",
    "        return 30.0, \"System Fallback\"\n",
    "\n",
    "# 1. GENERATE ROUTES\n",
    "graph, r1, r2, shelters = generate_cool_routes()\n",
    "\n",
    "if graph:\n",
    "    # 2. GET WEATHER\n",
    "    current_wbgt, station_name = get_nearest_wbgt_station(START_POINT[0], START_POINT[1])\n",
    "\n",
    "    # 3. RUN AI\n",
    "    pred_wbgt, trend, confidence = predict_trend(station_name, current_wbgt)\n",
    "    effective_wbgt = max(current_wbgt, pred_wbgt)\n",
    "    if NEA_HEATWAVE_ALERT: effective_wbgt = 35.0\n",
    "\n",
    "    # 4. REPORT\n",
    "    if effective_wbgt < 29: rec = \"‚úÖ Safe to Ride.\"\n",
    "    elif effective_wbgt < 31: rec = \"‚ö†Ô∏è CAUTION: Seek shade.\"\n",
    "    else: rec = \"üõë HIGH RISK: Stop.\"\n",
    "\n",
    "    print(f\"\\nüìä REPORT: {station_name}\")\n",
    "    print(f\"   Current: {current_wbgt}¬∞C | Forecast: {pred_wbgt:.1f}¬∞C\")\n",
    "\n",
    "    # 5. EXPORT KML (CLEAN LABELS)\n",
    "    kml = simplekml.Kml()\n",
    "\n",
    "    def add_route(route, color, name, description):\n",
    "        ls = kml.newlinestring(name=name)\n",
    "        coords = []\n",
    "        for u, v in zip(route[:-1], route[1:]):\n",
    "            d = graph.get_edge_data(u, v)[0]\n",
    "            if 'geometry' in d:\n",
    "                xs, ys = d['geometry'].xy\n",
    "                coords.extend(list(zip(xs, ys)))\n",
    "            else:\n",
    "                coords.append((graph.nodes[u]['x'], graph.nodes[u]['y']))\n",
    "                coords.append((graph.nodes[v]['x'], graph.nodes[v]['y']))\n",
    "        ls.coords = coords\n",
    "        ls.style.linestyle.color = color\n",
    "        ls.style.linestyle.width = 5\n",
    "        ls.description = description\n",
    "\n",
    "    # üß† FUZZY LOGIC + CLEAN LABELS\n",
    "    def check_similarity(route_a, route_b):\n",
    "        set_a = set(route_a)\n",
    "        set_b = set(route_b)\n",
    "        intersection = len(set_a.intersection(set_b))\n",
    "        union = len(set_a.union(set_b))\n",
    "        return intersection / union\n",
    "\n",
    "    sim_score = check_similarity(r1, r2)\n",
    "    print(f\"   üîç Route Similarity Score: {sim_score*100:.1f}%\")\n",
    "\n",
    "    if sim_score > 0.90:  # If >90% similar, merge them\n",
    "        print(\"   üí° Insight: Routes are effectively identical (Merged).\")\n",
    "        # MERGED LABEL\n",
    "        add_route(r2, simplekml.Color.green, \"üåü Recommended Route\",\n",
    "                  f\"<b>Smart Choice</b><br>The fastest path is also the coolest.<br>No detour needed.<br><br>Temp: {effective_wbgt:.1f}¬∞C\")\n",
    "    else:\n",
    "        print(\"   üí° Insight: A distinct cooler detour exists.\")\n",
    "        # DIVERGENT LABELS\n",
    "        add_route(r1, simplekml.Color.red, \"‚ö° Fastest Route (Exposed)\",\n",
    "                  f\"<b>Direct Path</b><br>Shortest time, but higher heat exposure.<br><br>Temp: {effective_wbgt:.1f}¬∞C\")\n",
    "        add_route(r2, simplekml.Color.green, \"üåø Cool Route (Shaded)\",\n",
    "                  f\"<b>Shaded Detour</b><br>Maximized tree canopy coverage.<br>Lower heat stress.<br><br>Temp: {effective_wbgt:.1f}¬∞C\")\n",
    "\n",
    "    # Add Shelters\n",
    "    if shelters:\n",
    "        for name, lat, lon in shelters:\n",
    "            p = kml.newpoint(name=f\"üßä {name}\", coords=[(lon, lat)])\n",
    "            p.style.iconstyle.icon.href = 'http://googleusercontent.com/maps.google.com/mapfiles/kml/shapes/snowflake_simple.png'\n",
    "\n",
    "    # 6. SAVE\n",
    "    if not os.path.exists('output'): os.makedirs('output')\n",
    "    constant_filename = \"output/latest_route.kml\"\n",
    "    kml.save(constant_filename)\n",
    "\n",
    "    print(f\"\\nüéâ SUCCESS! Download '{constant_filename}'\")\n",
    "else:\n",
    "    print(\"‚ùå Critical Error: Route Generation Failed.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
