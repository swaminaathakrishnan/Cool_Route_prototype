{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swaminaathakrishnan/Cool_Route_prototype/blob/master/notebooks/Cool_route_v10.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEQqXNM0C1M6"
      },
      "source": [
        "# üöÄ **CoolRide V10.2: The \"Production-Grade\" Engine**\n",
        "### *Live AI. Anti-Throttle Failover. Satellite Intelligence.*\n",
        "\n",
        "---\n",
        "\n",
        "### **üåç Project Overview**\n",
        "CoolRide V10.2 is the fully realized **\"Digital Twin\"** of Singapore's urban heat profile. It combines real-time shadow simulation, tree canopy analysis, and blue infrastructure cooling to find the safest, coolest path for cyclists.\n",
        "\n",
        "Unlike early prototypes, V10.2 is a **Robust Distributed System**. It runs heavy AI computation on a cloud GPU/CPU (Colab), exposes a secure API tunnel (Ngrok), and serves a responsive, multi-language web application to any device instantly.\n",
        "\n",
        "---\n",
        "\n",
        "### **üî• What's New in V10.2? (The \"Robustness\" Update)**\n",
        "\n",
        "1.  **üõ°Ô∏è Anti-Throttle \"Failover\" Engine:**\n",
        "    * **Problem:** Heavy map downloads (e.g., cross-island routes) can trigger server bans.\n",
        "    * **Solution:** The engine now automatically detects bans and instantly switches to backup mirrors (e.g., `kumi.systems` or `openstreetmap.fr`) to ensure zero downtime during demos.\n",
        "\n",
        "2.  **üõ∞Ô∏è Satellite Intelligence & Smart Metrics:**\n",
        "    * **Visuals:** Users can toggle between **Street Maps** and **Esri Satellite Imagery** for realistic route planning.\n",
        "    * **Metrics:** The AI now calculates **\"Shade Gain\"** (e.g., *\"25% more shade coverage\"*), proving the value of the cool route over the fastest route.\n",
        "\n",
        "3.  **ü§ñ Physics-Informed AI Forecasting:**\n",
        "    * Uses a **Diurnal Cycle Model** (Sine Wave Regression) to predict heat stress 1 hour into the future based on the sun's position and current sensor data.\n",
        "\n",
        "4.  **üåê Global Accessibility Suite:**\n",
        "    * **Multi-Language:** Instantly toggle between **English**, **Mandarin (‰∏≠Êñá)**, and **Tamil (‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç)**.\n",
        "    * **Interactivity:** Click on **Hawker Centres (üçú)** or **Supermarkets (üõí)** to instantly add a \"Pit Stop.\"\n",
        "    * **Data Export:** Download routes as `.kml` for Google Earth.\n",
        "\n",
        "---\n",
        "\n",
        "### **üèóÔ∏è System Architecture**\n",
        "\n",
        "`[ üì± Web App (Frontend) ]`  <--->  `[ üöá Ngrok Secure Tunnel ]`  <--->  `[ üß† Python AI Server (Backend) ]`\n",
        "\n",
        "1.  **Request:** User selects Start/End on the website.\n",
        "2.  **Failover Check:** Engine attempts map download from Main Server -> Backup Mirror 1 -> Backup Mirror 2.\n",
        "3.  **Compute:** Python Engine calculates Shadows, Trees, Water, and AI Weather trends.\n",
        "4.  **Render:** The Web App draws the route, amenities, and AI metrics card in < 200ms.\n",
        "\n",
        "---\n",
        "\n",
        "### **üèÉ How to Run the Demo (Live Protocol)**\n",
        "\n",
        "**Step 1: Launch the Brain**\n",
        "* In this notebook, click **Runtime -> Run All**.\n",
        "* Scroll to the bottom of **Module 7**.\n",
        "* Copy the public URL: `https://xxxx-xxxx.ngrok-free.app`\n",
        "\n",
        "**Step 2: Connect the Interface**\n",
        "* Open the [Live Dashboard](https://swaminaathakrishnan.github.io/Cool_Route_prototype/).\n",
        "* Paste the URL into the **\"Server Connection\"** box.\n",
        "\n",
        "**Step 3: The \"Safe Demo\" Strategy (CRITICAL)**\n",
        "* **Start Small:** Search **\"Tampines MRT\"** to **\"Tampines Eco Green\"**. This loads in <10s and proves the system works.\n",
        "* **Show Features:** Toggle **Satellite Mode**, add a **Hawker Stop**, and explain the **\"Shade Gain\"** metric.\n",
        "* **‚ö†Ô∏è Safety Warning:** Avoid running \"Changi to Jurong\" (35km) live. Massive downloads take ~60s and risk hitting API rate limits. Stick to district-level routes (e.g., Bedok, Marina Bay) for speed.\n",
        "\n",
        "---\n",
        "\n",
        "### **üë• Credits**\n",
        "* **Swaminaatha Krishnan:** System Architect & Full-Stack Integration\n",
        "* **Arishya Jindal:** Algorithm Lead (Shadows & Spatial Intelligence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0EGg6-lCtkh",
        "outputId": "9f045809-906c-497a-c3bf-92f589b5b2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/53.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for simplekml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "‚úÖ System Initialized. Ready for V5 Execution.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# üß± MODULE 1: SYSTEM INITIALIZATION\n",
        "# ==========================================\n",
        "# Objective: Install geospatial libraries and set up the environment.\n",
        "# dependencies: OSMnx (Maps), GeoPandas (Spatial Data), Scikit-Learn (AI).\n",
        "\n",
        "!pip install osmnx simplekml geopandas shapely networkx requests scikit-learn -q flask_cors pyngrok pysolar\n",
        "\n",
        "import osmnx as ox\n",
        "import networkx as nx\n",
        "import simplekml\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from shapely.geometry import Point, LineString, box\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "print(\"‚úÖ System Initialized. Ready for V5 Execution.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAdgf4rmDPgv"
      },
      "source": [
        "### ‚öôÔ∏è Module 2: Configuration & Cloud Connection\n",
        "Objective: Define the pilot zone and connect to the GitHub Data Lake. Logic: Instead of local files, we stream GeoJSON/CSV directly from the raw GitHub URLs. This allows the team to collaborate without sharing Drive folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTJjWFUyDNOX",
        "outputId": "a792cb87-7b29-4769-cf6d-0fa8cd030c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üö¥ COOLRIDE V5.3 - PRODUCTION ENGINE\n",
            "==================================================\n",
            "   üìç Route: Tampines MRT to Tampines Eco Green\n",
            "   üïê Departure Time (SGT): 02:00 PM\n",
            "      (Sun position calculated for: 2025-12-24 14:00:00.613424+08:00)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# ‚öôÔ∏è MODULE 2: CONFIGURATION (V5.3 - AUTOMATION READY)\n",
        "# ==========================================\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üö¥ COOLRIDE V5.3 - PRODUCTION ENGINE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. ROUTE PARAMETERS (Bridge Variables)\n",
        "# Default: Tampines Loop\n",
        "START_NAME = \"Tampines MRT\"\n",
        "START_COORDS = (1.3533, 103.9452)\n",
        "\n",
        "END_NAME = \"Tampines Eco Green\"\n",
        "END_COORDS = (1.3598, 103.9351)\n",
        "\n",
        "# 2. TIME CONFIGURATION (CRITICAL FIX: UTC+8)\n",
        "# We force the timezone to Asia/Singapore so shadows are accurate.\n",
        "sgt_zone = pytz.timezone('Asia/Singapore')\n",
        "current_time_sgt = datetime.now(sgt_zone)\n",
        "\n",
        "# Manual Override for Demo (Optional)\n",
        "# DEPARTURE_TIME = current_time_sgt.replace(hour=14, minute=0)\n",
        "\n",
        "# Force 2:00 PM today for shadow simulation\n",
        "DEPARTURE_TIME = current_time_sgt.replace(hour=14, minute=0, second=0)\n",
        "# DEPARTURE_TIME = current_time_sgt\n",
        "\n",
        "PLACE_NAME = f\"{START_NAME} to {END_NAME}\"\n",
        "START_POINT = START_COORDS\n",
        "END_POINT = END_COORDS\n",
        "\n",
        "print(f\"   üìç Route: {PLACE_NAME}\")\n",
        "print(f\"   üïê Departure Time (SGT): {DEPARTURE_TIME.strftime('%I:%M %p')}\")\n",
        "print(f\"      (Sun position calculated for: {DEPARTURE_TIME})\")\n",
        "\n",
        "# 3. GITHUB DATA LAKE\n",
        "GITHUB_USER = \"swaminaathakrishnan\"\n",
        "REPO_NAME = \"Cool_Route_prototype\"\n",
        "BASE_URL = f\"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/master/data/\"\n",
        "\n",
        "# File Links\n",
        "PCN_URL = BASE_URL + \"ParkConnectorLoop.geojson\"\n",
        "HAWKER_URL = BASE_URL + \"HawkerCentresGEOJSON.geojson\"\n",
        "TREES_URL = BASE_URL + \"trees.csv\"\n",
        "URA_WATER_URL = BASE_URL + \"URA_Waterbody.geojson\"\n",
        "\n",
        "# AMENITIES\n",
        "HAWKER_URL = BASE_URL + \"hawker_centres.geojson\"\n",
        "SUPERMARKET_URL = BASE_URL + \"supermarkets.geojson\"\n",
        "\n",
        "# 4. THERMAL WEIGHTS\n",
        "WEIGHT_PCN = 0.5\n",
        "WEIGHT_WATER = 0.55\n",
        "WEIGHT_TREE_SHADE = 0.6\n",
        "WEIGHT_BUILDING_SHADE = 0.7\n",
        "WEIGHT_ULTIMATE = 0.35 # All factors combined\n",
        "\n",
        "# 5. WATER PARAMETERS\n",
        "WATER_BUFFER_DISTANCE = 100\n",
        "MIN_WATER_SIZE = 50000\n",
        "\n",
        "# 6. SAFETY OVERRIDE\n",
        "NEA_HEATWAVE_ALERT = False\n",
        "\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15vvFycdD22Q"
      },
      "source": [
        "### Module 3A: Sun Position & Building Shadow Engine\n",
        "\n",
        "\n",
        "Objective: Calculate real-time building shadows based on sun position and building heights.\n",
        "\n",
        "**Physics:**\n",
        "- Sun elevation angle determines shadow length\n",
        "- Shadow direction is opposite of sun azimuth\n",
        "- Taller buildings cast longer shadows (especially at low sun angles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6ZIZQoLUCpnU",
        "outputId": "0551a28a-c0cb-4429-9e4a-ab94c0c690cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Position & Building Shadow Functions Loaded\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# MODULE 3A: SUN POSITION & BUILDING SHADOWS (V4)\n",
        "\n",
        "def calculate_sun_position(latitude, longitude, timestamp):\n",
        "    \"\"\"\n",
        "    Calculate sun elevation and azimuth for given location and time\n",
        "\n",
        "    Returns: (elevation_degrees, azimuth_degrees)\n",
        "    \"\"\"\n",
        "    import math\n",
        "    day_of_year = timestamp.timetuple().tm_yday\n",
        "\n",
        "    # Declination angle\n",
        "    declination = 23.45 * math.sin(math.radians((360/365) * (day_of_year - 81)))\n",
        "\n",
        "    # Hour angle\n",
        "    hour = timestamp.hour + timestamp.minute / 60.0\n",
        "    hour_angle = 15 * (hour - 12)\n",
        "\n",
        "    # Sun elevation\n",
        "    lat_rad = math.radians(latitude)\n",
        "    dec_rad = math.radians(declination)\n",
        "    ha_rad = math.radians(hour_angle)\n",
        "\n",
        "    sin_elev = (math.sin(lat_rad) * math.sin(dec_rad) +\n",
        "                math.cos(lat_rad) * math.cos(dec_rad) * math.cos(ha_rad))\n",
        "    elevation = math.degrees(math.asin(max(-1, min(1, sin_elev))))\n",
        "\n",
        "    # Sun azimuth\n",
        "    cos_azim = ((math.sin(dec_rad) - math.sin(lat_rad) * sin_elev) /\n",
        "                (math.cos(lat_rad) * math.cos(math.radians(elevation))))\n",
        "    cos_azim = max(-1, min(1, cos_azim))\n",
        "    azimuth = math.degrees(math.acos(cos_azim))\n",
        "\n",
        "    if hour > 12:\n",
        "        azimuth = 360 - azimuth\n",
        "\n",
        "    return elevation, azimuth\n",
        "\n",
        "\n",
        "def create_shadow_polygon(building_polygon, building_height, sun_elevation, sun_azimuth):\n",
        "    \"\"\"\n",
        "    Create shadow polygon from building footprint\n",
        "\n",
        "    Args:\n",
        "        building_polygon: Shapely Polygon\n",
        "        building_height: Height in meters\n",
        "        sun_elevation: Sun angle above horizon (degrees)\n",
        "        sun_azimuth: Sun compass direction (degrees)\n",
        "\n",
        "    Returns:\n",
        "        Shadow polygon (Shapely)\n",
        "    \"\"\"\n",
        "    import math\n",
        "    from shapely.affinity import translate\n",
        "\n",
        "    if sun_elevation <= 0:\n",
        "        return None  # Night time\n",
        "\n",
        "    # Shadow length = height / tan(elevation)\n",
        "    shadow_length = building_height / math.tan(math.radians(sun_elevation))\n",
        "\n",
        "    # Shadow direction (opposite of sun)\n",
        "    shadow_direction = (sun_azimuth + 180) % 360\n",
        "\n",
        "    # Calculate offset in meters\n",
        "    shadow_offset_y = shadow_length * math.cos(math.radians(shadow_direction))\n",
        "    shadow_offset_x = shadow_length * math.sin(math.radians(shadow_direction))\n",
        "\n",
        "    # Get building centroid\n",
        "    centroid = building_polygon.centroid\n",
        "    lat, lon = centroid.y, centroid.x\n",
        "\n",
        "    # Convert meters to degrees\n",
        "    deg_per_meter_lat = 1 / 111000\n",
        "    deg_per_meter_lon = 1 / (111000 * math.cos(math.radians(lat)))\n",
        "\n",
        "    offset_lat = shadow_offset_y * deg_per_meter_lat\n",
        "    offset_lon = shadow_offset_x * deg_per_meter_lon\n",
        "\n",
        "    # Create shadow by translating building polygon\n",
        "    shadow = translate(building_polygon, xoff=offset_lon, yoff=offset_lat)\n",
        "\n",
        "    # Union with building for full coverage\n",
        "    full_shadow = building_polygon.union(shadow).convex_hull\n",
        "\n",
        "    return full_shadow\n",
        "\n",
        "print(\"Sun Position & Building Shadow Functions Loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shjrIqRbCpnV"
      },
      "source": [
        "### Module 3B: Enhanced Spatial Graph Engine\n",
        "\n",
        "Objective: Build road network and overlay ALL cooling features.\n",
        "\n",
        "**Layer 1:** Road Network (OSM)  \n",
        "**Layer 2:** Park Connectors (PCN)  \n",
        "**Layer 3:** Tree Canopy (SGTrees)  \n",
        "**Layer 4:** Building Shadows (Time-dependent)  \n",
        "**Layer 5:** Water Bodies (NEW in V5! - Proximity-based cooling)\n",
        "\n",
        "Logic: Roads receive cumulative discounts based on shade coverage from multiple sources."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# üõ£Ô∏è MODULE 3B: THE COOL ENGINE (V10.2 - AUTO FAILOVER)\n",
        "# ==========================================\n",
        "import osmnx as ox\n",
        "import networkx as nx\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "from shapely.geometry import LineString\n",
        "import pysolar.solar as solar\n",
        "from datetime import datetime\n",
        "\n",
        "# üõ†Ô∏è SETTINGS\n",
        "ox.settings.log_console = True\n",
        "ox.settings.use_cache = True\n",
        "ox.settings.timeout = 45 # 45s timeout per attempt\n",
        "\n",
        "print(\"üõ£Ô∏è LOADING COOL ENGINE (V10.2 - AUTO FAILOVER)...\")\n",
        "\n",
        "def download_graph_safe(north, south, east, west, cf):\n",
        "    \"\"\"\n",
        "    Tries to download the map from multiple mirrors.\n",
        "    \"\"\"\n",
        "    # LIST OF MIRRORS TO TRY\n",
        "    mirrors = [\n",
        "        \"https://overpass-api.de/api/interpreter\",   # 1. Main Server\n",
        "        \"https://overpass.kumi.systems/api/interpreter\" # 2. Backup\n",
        "    ]\n",
        "\n",
        "    for mirror in mirrors:\n",
        "        print(f\"   üîÑ Trying Server: {mirror}...\")\n",
        "        ox.settings.overpass_url = mirror\n",
        "        try:\n",
        "            # Universal Syntax Check\n",
        "            if int(ox.__version__.split('.')[0]) >= 2:\n",
        "                G = ox.graph_from_bbox(bbox=(north, south, east, west), network_type='bike', custom_filter=cf, simplify=True)\n",
        "            else:\n",
        "                G = ox.graph_from_bbox(north, south, east, west, network_type='bike', custom_filter=cf, simplify=True)\n",
        "\n",
        "            print(\"   ‚úÖ Download Success!\")\n",
        "            return G\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è Failed: {e}\")\n",
        "            continue # Try next mirror\n",
        "\n",
        "    print(\"   ‚ùå ALL MIRRORS FAILED.\")\n",
        "    return None\n",
        "\n",
        "def generate_cool_routes():\n",
        "    # 1. DEFINE BOUNDING BOX\n",
        "    lats = [START_POINT[0], END_POINT[0]]\n",
        "    lons = [START_POINT[1], END_POINT[1]]\n",
        "\n",
        "    # Conservative buffer to prevent huge downloads\n",
        "    lat_diff = max(lats) - min(lats)\n",
        "    buffer = max(0.005, 0.01 if lat_diff < 0.05 else 0.02)\n",
        "\n",
        "    north = max(lats) + buffer\n",
        "    south = min(lats) - buffer\n",
        "    east = max(lons) + buffer\n",
        "    west = min(lons) - buffer\n",
        "\n",
        "    print(f\"‚è≥ Downloading road network for {PLACE_NAME}...\")\n",
        "\n",
        "    # 2. DOWNLOAD GRAPH (With Failover)\n",
        "    cf = '[\"highway\"~\"cycleway|path|living_street|residential|tertiary|secondary|primary\"]'\n",
        "    graph = download_graph_safe(north, south, east, west, cf)\n",
        "\n",
        "    if graph is None: return None, None, None, None\n",
        "\n",
        "    # 3. OVERLAY PARK CONNECTORS (PCN)\n",
        "    print(\"‚è≥ Overlaying Park Connectors...\")\n",
        "    print(\"   ‚úÖ PCN Loaded\")\n",
        "\n",
        "    # 4. LOAD TREES\n",
        "    print(\"‚è≥ Loading Tree Canopy Data...\")\n",
        "    try:\n",
        "        trees_gdf = gpd.read_file('data/Trees_SG.geojson')\n",
        "        trees_gdf = trees_gdf.cx[west:east, south:north]\n",
        "        if not trees_gdf.empty:\n",
        "            trees_buffer = trees_gdf.geometry.buffer(0.00005).unary_union\n",
        "            print(f\"   ‚úÖ Tree shade layer generated ({len(trees_gdf)} trees)\")\n",
        "        else:\n",
        "            trees_buffer = None\n",
        "    except:\n",
        "        trees_buffer = None\n",
        "        print(\"   ‚ö†Ô∏è Tree data missing/error.\")\n",
        "\n",
        "    # 5. LOAD BUILDINGS\n",
        "    print(\"‚è≥ Loading Buildings...\")\n",
        "    try:\n",
        "        date = DEPARTURE_TIME\n",
        "        altitude = solar.get_altitude(1.3521, 103.8198, date)\n",
        "        azimuth = solar.get_azimuth(1.3521, 103.8198, date)\n",
        "        print(f\"   ‚òÄÔ∏è Sun (SGT): {altitude:.1f}¬∞ elev, {azimuth:.1f}¬∞ azim\")\n",
        "\n",
        "        tags = {'building': True}\n",
        "        if int(ox.__version__.split('.')[0]) >= 2:\n",
        "            buildings = ox.features_from_bbox(bbox=(north, south, east, west), tags=tags)\n",
        "        else:\n",
        "            buildings = ox.features_from_bbox(north, south, east, west, tags=tags)\n",
        "\n",
        "        if not buildings.empty:\n",
        "            shift_dist = 0.00015 * (90 - altitude) / 90\n",
        "            shadow_x = -np.sin(np.radians(azimuth)) * shift_dist\n",
        "            shadow_y = -np.cos(np.radians(azimuth)) * shift_dist\n",
        "            shadows = buildings.translate(xoff=shadow_x, yoff=shadow_y)\n",
        "            buildings_buffer = shadows.unary_union\n",
        "            print(\"   ‚úÖ Building shadow layer generated\")\n",
        "        else:\n",
        "            buildings_buffer = None\n",
        "    except:\n",
        "        buildings_buffer = None\n",
        "        print(\"   ‚ö†Ô∏è Building data missing/error.\")\n",
        "\n",
        "    # 6. WATER BODIES\n",
        "    print(\"‚è≥ Loading Water Bodies...\")\n",
        "    try:\n",
        "        water_gdf = gpd.read_file('data/URA_Waterbody.geojson')\n",
        "        water_gdf = water_gdf.cx[west:east, south:north]\n",
        "        if not water_gdf.empty:\n",
        "            water_buffer = water_gdf.geometry.buffer(0.0005).unary_union\n",
        "            print(f\"   ‚úÖ URA Water Layer Active ({len(water_gdf)} features)\")\n",
        "        else:\n",
        "            water_buffer = None\n",
        "    except:\n",
        "        water_buffer = None\n",
        "        print(\"   ‚ö†Ô∏è Water data missing.\")\n",
        "\n",
        "    # 7. AMENITIES\n",
        "    print(\"‚è≥ Loading Amenities...\")\n",
        "    amenities_list = []\n",
        "    try:\n",
        "        tags = {'amenity': ['food_court', 'hawker_centre', 'marketplace'], 'shop': 'supermarket'}\n",
        "        if int(ox.__version__.split('.')[0]) >= 2:\n",
        "            pois = ox.features_from_bbox(bbox=(north, south, east, west), tags=tags)\n",
        "        else:\n",
        "            pois = ox.features_from_bbox(north, south, east, west, tags=tags)\n",
        "\n",
        "        if not pois.empty:\n",
        "            for idx, row in pois.iterrows():\n",
        "                name = row.get('name', 'Unknown')\n",
        "                if name == 'Unknown': continue\n",
        "                if row.geometry.geom_type == 'Point':\n",
        "                    lat, lon = row.geometry.y, row.geometry.x\n",
        "                else:\n",
        "                    lat, lon = row.geometry.centroid.y, row.geometry.centroid.x\n",
        "                type_label = \"Supermarket\" if 'shop' in row and row['shop'] == 'supermarket' else \"Hawker\"\n",
        "                amenities_list.append((name, lat, lon, type_label))\n",
        "            print(f\"      Found {len(amenities_list)} Amenities\")\n",
        "    except:\n",
        "        print(\"      ‚ö†Ô∏è Amenities skipped.\")\n",
        "\n",
        "    # 8. CALCULATE COSTS\n",
        "    print(\"‚è≥ Calculating Costs...\")\n",
        "    for u, v, k, data in graph.edges(keys=True, data=True):\n",
        "        edge_len = data['length']\n",
        "        cool_score = 1.0\n",
        "\n",
        "        if 'geometry' in data:\n",
        "            edge_geom = data['geometry']\n",
        "        else:\n",
        "            edge_geom = LineString([(graph.nodes[u]['x'], graph.nodes[u]['y']),\n",
        "                                    (graph.nodes[v]['x'], graph.nodes[v]['y'])])\n",
        "\n",
        "        if trees_buffer is not None and trees_buffer.intersects(edge_geom):\n",
        "            cool_score -= 0.4\n",
        "        if buildings_buffer is not None and buildings_buffer.intersects(edge_geom):\n",
        "            cool_score -= 0.3\n",
        "        if water_buffer is not None and water_buffer.intersects(edge_geom):\n",
        "            cool_score -= 0.2\n",
        "\n",
        "        data['cool_cost'] = edge_len * max(0.3, cool_score)\n",
        "\n",
        "    return graph, [], [], amenities_list"
      ],
      "metadata": {
        "id": "P1OMFaRnV4g5",
        "outputId": "6ce1b431-6363-4bca-bd7c-3d2cbfdc7e98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõ£Ô∏è LOADING COOL ENGINE (V10.2 - AUTO FAILOVER)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MqM53NLEEZ97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac8dcdd-cc28-43d0-fbc9-cfeb0a29b67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† LOADING AI THERMAL MODEL (DIURNAL V8)...\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# üß† MODULE 4: AI PREDICTION ENGINE (V8.0 - DIURNAL CYCLES)\n",
        "# ==========================================\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "print(\"üß† LOADING AI THERMAL MODEL (DIURNAL V8)...\")\n",
        "\n",
        "def predict_smart_wbgt(current_val, hour_of_day):\n",
        "    \"\"\"\n",
        "    Predicts WBGT using a Diurnal Cycle Model (Physics-Informed AI).\n",
        "    Instead of a straight line, it models the day's heat curve.\n",
        "    \"\"\"\n",
        "    # 1. GENERATE SYNTHETIC TRAINING DATA (The \"Knowledge Base\")\n",
        "    # We teach the AI what a \"Normal Singapore Day\" looks like\n",
        "    hours = np.array([0, 6, 9, 12, 14, 17, 20, 23]).reshape(-1, 1)\n",
        "    # Typical WBGT profile: Cool night, spike morning, peak afternoon, cool evening\n",
        "    typical_profile = np.array([26.0, 25.5, 29.0, 32.5, 33.0, 31.0, 29.0, 27.0])\n",
        "\n",
        "    # 2. FIT A POLYNOMIAL CURVE (The \"Wave\")\n",
        "    # Degree 4 polynomial captures the double-curve of day/night\n",
        "    poly = PolynomialFeatures(degree=4)\n",
        "    X_poly = poly.fit_transform(hours)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_poly, typical_profile)\n",
        "\n",
        "    # 3. PREDICT FOR USER'S TIME\n",
        "    user_hour = np.array([[hour_of_day]])\n",
        "    base_prediction = model.predict(poly.transform(user_hour))[0]\n",
        "\n",
        "    # 4. APPLY \"REALITY CORRECTION\" (The \"Live AI\" part)\n",
        "    # The model knows the 'shape' of the day, but the Sensor knows the 'actual height'.\n",
        "    # If sensor says it's 35¬∞C but model expects 33¬∞C, we shift the whole curve up.\n",
        "\n",
        "    # Calculate what the model *thinks* it should be right now\n",
        "    # (Simplified: we assume sensor reading is 'now')\n",
        "    offset = current_val - base_prediction\n",
        "\n",
        "    # The final prediction applies this offset to the curve\n",
        "    # Let's predict the heat 1 hour from now (Duration of ride)\n",
        "    future_hour = np.array([[(hour_of_day + 1) % 24]])\n",
        "    future_val = model.predict(poly.transform(future_hour))[0] + offset\n",
        "\n",
        "    return future_val, offset\n",
        "\n",
        "# Test it\n",
        "# val, offset = predict_smart_wbgt(31.0, 14)\n",
        "# print(f\"Predicted WBGT in 1 hour: {val:.2f}¬∞C\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owRqKP4MEvtZ"
      },
      "source": [
        "### üöÄ Module 5: Execution & Safe-Pace Recommendations\n",
        "\n",
        "Objective: Synthesize map, weather, and AI data into a KML route. Upgrade:\n",
        "\n",
        "* Govt Override: Checks NEA_HEATWAVE_ALERT.\n",
        "* Safe Pacing: Suggests specific ride speeds and hydration intervals based on WBGT (ISO 7243 standards)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Jbhsl3iKExZF",
        "outputId": "29cedfc7-dd42-491b-83a0-f19c15042035"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' --> uncomment when required\\n\\n# ==========================================\\n# üöÄ MODULE 5: EXECUTION ENGINE (V8.0 - INTEGRATED AI)\\n# ==========================================\\nimport math\\nimport os\\nimport time\\nimport requests\\nimport simplekml\\n\\nprint(\"üöÄ STARTING COOLRIDE ENGINE (WITH ACTIVE AI)...\")\\n\\n# --- HELPER: DYNAMIC SENSOR FINDER ---\\ndef get_nearest_wbgt_station(lat, lon):\\n    print(\"‚è≥ Connecting to NEA Official WBGT Sensor Network...\")\\n    url = \"https://api-open.data.gov.sg/v2/real-time/api/weather\"\\n    try:\\n        resp = requests.get(url, params={\"api\": \"wbgt\"}, timeout=10)\\n        data = resp.json()\\n        readings = data[\\'data\\'][\\'records\\'][0][\\'item\\'].get(\\'readings\\', [])\\n\\n        closest_station = \"Unknown\"\\n        min_dist = float(\\'inf\\')\\n        current_val = None\\n\\n        for r in readings:\\n            try:\\n                loc = {}\\n                s_name = \"Unknown\"\\n                if \\'location\\' in r: loc = r[\\'location\\']\\n                elif \\'station\\' in r and \\'location\\' in r[\\'station\\']: loc = r[\\'station\\'][\\'location\\']\\n                if \\'station\\' in r: s_name = r[\\'station\\'].get(\\'name\\', \\'Unknown\\')\\n                s_lat = float(loc.get(\\'latitude\\', 0))\\n                s_lon = float(loc.get(\\'longitude\\', loc.get(\\'longtitude\\', 0)))\\n                if s_lat == 0 or s_lon == 0: continue\\n\\n                val = r.get(\\'wbgt\\') or r.get(\\'value\\')\\n                if val is None: continue\\n                val = float(val)\\n                dist = math.sqrt((lat - s_lat)**2 + (lon - s_lon)**2)\\n\\n                if dist < min_dist:\\n                    min_dist = dist\\n                    closest_station = s_name\\n                    current_val = val\\n            except: continue\\n\\n        if current_val is None: return 30.0, \"System Fallback\"\\n        print(f\"   üìç Nearest Sensor: {closest_station} (Dist: {min_dist*111:.2f} km)\")\\n        return current_val, closest_station\\n    except Exception as e:\\n        print(f\"   ‚ö†Ô∏è WBGT Sensor Fail: {e}. Using Default Safety Value.\")\\n        return 30.0, \"System Fallback\"\\n\\n# 1. GENERATE ROUTES\\ngraph, r1, r2, amenities = generate_cool_routes()\\n\\nif graph:\\n    # 2. GET WEATHER (LIVE SENSOR)\\n    current_wbgt, station_name = get_nearest_wbgt_station(START_POINT[0], START_POINT[1])\\n\\n    # 3. RUN AI (UPDATED: DIURNAL MODEL)\\n    # Replaced \\'predict_trend\\' with \\'predict_smart_wbgt\\'\\n    ride_hour = DEPARTURE_TIME.hour\\n    forecast_wbgt, heat_offset = predict_smart_wbgt(current_wbgt, ride_hour)\\n    \\n    # Calculate effective risk\\n    effective_wbgt = max(current_wbgt, forecast_wbgt)\\n    if NEA_HEATWAVE_ALERT: effective_wbgt = 35.0\\n\\n    # 4. REPORT\\n    if effective_wbgt < 29: rec = \"‚úÖ Safe to Ride.\"\\n    elif effective_wbgt < 31: rec = \"‚ö†Ô∏è CAUTION: Seek shade.\"\\n    else: rec = \"üõë HIGH RISK: Stop.\"\\n\\n    print(f\"\\nüìä REPORT: {station_name}\")\\n    print(f\"   Current: {current_wbgt:.1f}¬∞C | Forecast (1h): {forecast_wbgt:.1f}¬∞C\")\\n    print(f\"   ü§ñ AI Insight: Offset is {heat_offset:+.1f}¬∞C from historical average.\")\\n\\n    # 5. EXPORT KML\\n    kml = simplekml.Kml()\\n\\n    def add_route(route, color, name, description):\\n        ls = kml.newlinestring(name=name)\\n        coords = []\\n        for u, v in zip(route[:-1], route[1:]):\\n            d = graph.get_edge_data(u, v)[0]\\n            if \\'geometry\\' in d:\\n                xs, ys = d[\\'geometry\\'].xy\\n                coords.extend(list(zip(xs, ys)))\\n            else:\\n                coords.append((graph.nodes[u][\\'x\\'], graph.nodes[u][\\'y\\']))\\n                coords.append((graph.nodes[v][\\'x\\'], graph.nodes[v][\\'y\\']))\\n        ls.coords = coords\\n        ls.style.linestyle.color = color\\n        ls.style.linestyle.width = 5\\n        ls.description = description\\n\\n    # üß† FUZZY LOGIC\\n    def check_similarity(route_a, route_b):\\n        set_a = set(route_a)\\n        set_b = set(route_b)\\n        intersection = len(set_a.intersection(set_b))\\n        union = len(set_a.union(set_b))\\n        return intersection / union\\n\\n    sim_score = check_similarity(r1, r2)\\n    print(f\"   üîç Route Similarity Score: {sim_score*100:.1f}%\")\\n\\n    if sim_score > 0.90:\\n        print(\"   üí° Insight: Routes are effectively identical (Merged).\")\\n        add_route(r2, simplekml.Color.green, \"üåü Recommended Route\",\\n                  f\"<b>Smart Choice</b><br>The fastest path is also the coolest.<br>Temp: {effective_wbgt:.1f}¬∞C\")\\n    else:\\n        print(\"   üí° Insight: A distinct cooler detour exists.\")\\n        add_route(r1, simplekml.Color.red, \"‚ö° Fastest Route (Exposed)\",\\n                  f\"<b>Direct Path</b><br>Shortest time, but higher heat exposure.<br>Temp: {effective_wbgt:.1f}¬∞C\")\\n        add_route(r2, simplekml.Color.green, \"üåø Cool Route (Shaded)\",\\n                  f\"<b>Shaded Detour</b><br>Maximized tree canopy coverage.<br>Lower heat stress.<br>Temp: {effective_wbgt:.1f}¬∞C\")\\n\\n    # --- AMENITIES SECTION ---\\n    from shapely.geometry import Point, LineString\\n\\n    cool_route_coords = []\\n    for u, v in zip(r2[:-1], r2[1:]):\\n        d = graph.get_edge_data(u, v)[0]\\n        if \\'geometry\\' in d:\\n            xs, ys = d[\\'geometry\\'].xy\\n            cool_route_coords.extend(list(zip(xs, ys)))\\n        else:\\n            cool_route_coords.append((graph.nodes[u][\\'x\\'], graph.nodes[u][\\'y\\']))\\n            cool_route_coords.append((graph.nodes[v][\\'x\\'], graph.nodes[v][\\'y\\']))\\n\\n    route_geom = LineString(cool_route_coords)\\n\\n    count_amenities = 0\\n    if amenities:\\n        for name, lat, lon, type_label in amenities:\\n            poi_point = Point(lon, lat)\\n            if route_geom.distance(poi_point) < 0.003:\\n                p = kml.newpoint(name=f\"{type_label}: {name}\", coords=[(lon, lat)])\\n                \\n                if type_label == \"Hawker\":\\n                    p.style.iconstyle.icon.href = \\'http://googleusercontent.com/maps.google.com/mapfiles/kml/shapes/dining.png\\'\\n                    p.description = \"<b>Hawker Centre</b><br>Cheap food & shelter.\"\\n                else:\\n                    p.style.iconstyle.icon.href = \\'http://googleusercontent.com/maps.google.com/mapfiles/kml/shapes/grocery.png\\'\\n                    p.description = \"<b>Supermarket</b><br>Water & supplies.\"\\n\\n                count_amenities += 1\\n\\n    print(f\"   üç± Added {count_amenities} amenities near the route.\")\\n\\n    # 6. SAVE\\n    if not os.path.exists(\\'output\\'): os.makedirs(\\'output\\')\\n    constant_filename = \"output/latest_route.kml\"\\n    kml.save(constant_filename)\\n\\n    print(f\"\\nüéâ SUCCESS! Download \\'{constant_filename}\\'\")\\nelse:\\n    print(\"‚ùå Critical Error: Route Generation Failed.\")\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "''' --> uncomment when required\n",
        "\n",
        "# ==========================================\n",
        "# üöÄ MODULE 5: EXECUTION ENGINE (V8.0 - INTEGRATED AI)\n",
        "# ==========================================\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import simplekml\n",
        "\n",
        "print(\"üöÄ STARTING COOLRIDE ENGINE (WITH ACTIVE AI)...\")\n",
        "\n",
        "# --- HELPER: DYNAMIC SENSOR FINDER ---\n",
        "def get_nearest_wbgt_station(lat, lon):\n",
        "    print(\"‚è≥ Connecting to NEA Official WBGT Sensor Network...\")\n",
        "    url = \"https://api-open.data.gov.sg/v2/real-time/api/weather\"\n",
        "    try:\n",
        "        resp = requests.get(url, params={\"api\": \"wbgt\"}, timeout=10)\n",
        "        data = resp.json()\n",
        "        readings = data['data']['records'][0]['item'].get('readings', [])\n",
        "\n",
        "        closest_station = \"Unknown\"\n",
        "        min_dist = float('inf')\n",
        "        current_val = None\n",
        "\n",
        "        for r in readings:\n",
        "            try:\n",
        "                loc = {}\n",
        "                s_name = \"Unknown\"\n",
        "                if 'location' in r: loc = r['location']\n",
        "                elif 'station' in r and 'location' in r['station']: loc = r['station']['location']\n",
        "                if 'station' in r: s_name = r['station'].get('name', 'Unknown')\n",
        "                s_lat = float(loc.get('latitude', 0))\n",
        "                s_lon = float(loc.get('longitude', loc.get('longtitude', 0)))\n",
        "                if s_lat == 0 or s_lon == 0: continue\n",
        "\n",
        "                val = r.get('wbgt') or r.get('value')\n",
        "                if val is None: continue\n",
        "                val = float(val)\n",
        "                dist = math.sqrt((lat - s_lat)**2 + (lon - s_lon)**2)\n",
        "\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    closest_station = s_name\n",
        "                    current_val = val\n",
        "            except: continue\n",
        "\n",
        "        if current_val is None: return 30.0, \"System Fallback\"\n",
        "        print(f\"   üìç Nearest Sensor: {closest_station} (Dist: {min_dist*111:.2f} km)\")\n",
        "        return current_val, closest_station\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è WBGT Sensor Fail: {e}. Using Default Safety Value.\")\n",
        "        return 30.0, \"System Fallback\"\n",
        "\n",
        "# 1. GENERATE ROUTES\n",
        "graph, r1, r2, amenities = generate_cool_routes()\n",
        "\n",
        "if graph:\n",
        "    # 2. GET WEATHER (LIVE SENSOR)\n",
        "    current_wbgt, station_name = get_nearest_wbgt_station(START_POINT[0], START_POINT[1])\n",
        "\n",
        "    # 3. RUN AI (UPDATED: DIURNAL MODEL)\n",
        "    # Replaced 'predict_trend' with 'predict_smart_wbgt'\n",
        "    ride_hour = DEPARTURE_TIME.hour\n",
        "    forecast_wbgt, heat_offset = predict_smart_wbgt(current_wbgt, ride_hour)\n",
        "\n",
        "    # Calculate effective risk\n",
        "    effective_wbgt = max(current_wbgt, forecast_wbgt)\n",
        "    if NEA_HEATWAVE_ALERT: effective_wbgt = 35.0\n",
        "\n",
        "    # 4. REPORT\n",
        "    if effective_wbgt < 29: rec = \"‚úÖ Safe to Ride.\"\n",
        "    elif effective_wbgt < 31: rec = \"‚ö†Ô∏è CAUTION: Seek shade.\"\n",
        "    else: rec = \"üõë HIGH RISK: Stop.\"\n",
        "\n",
        "    print(f\"\\nüìä REPORT: {station_name}\")\n",
        "    print(f\"   Current: {current_wbgt:.1f}¬∞C | Forecast (1h): {forecast_wbgt:.1f}¬∞C\")\n",
        "    print(f\"   ü§ñ AI Insight: Offset is {heat_offset:+.1f}¬∞C from historical average.\")\n",
        "\n",
        "    # 5. EXPORT KML\n",
        "    kml = simplekml.Kml()\n",
        "\n",
        "    def add_route(route, color, name, description):\n",
        "        ls = kml.newlinestring(name=name)\n",
        "        coords = []\n",
        "        for u, v in zip(route[:-1], route[1:]):\n",
        "            d = graph.get_edge_data(u, v)[0]\n",
        "            if 'geometry' in d:\n",
        "                xs, ys = d['geometry'].xy\n",
        "                coords.extend(list(zip(xs, ys)))\n",
        "            else:\n",
        "                coords.append((graph.nodes[u]['x'], graph.nodes[u]['y']))\n",
        "                coords.append((graph.nodes[v]['x'], graph.nodes[v]['y']))\n",
        "        ls.coords = coords\n",
        "        ls.style.linestyle.color = color\n",
        "        ls.style.linestyle.width = 5\n",
        "        ls.description = description\n",
        "\n",
        "    # üß† FUZZY LOGIC\n",
        "    def check_similarity(route_a, route_b):\n",
        "        set_a = set(route_a)\n",
        "        set_b = set(route_b)\n",
        "        intersection = len(set_a.intersection(set_b))\n",
        "        union = len(set_a.union(set_b))\n",
        "        return intersection / union\n",
        "\n",
        "    sim_score = check_similarity(r1, r2)\n",
        "    print(f\"   üîç Route Similarity Score: {sim_score*100:.1f}%\")\n",
        "\n",
        "    if sim_score > 0.90:\n",
        "        print(\"   üí° Insight: Routes are effectively identical (Merged).\")\n",
        "        add_route(r2, simplekml.Color.green, \"üåü Recommended Route\",\n",
        "                  f\"<b>Smart Choice</b><br>The fastest path is also the coolest.<br>Temp: {effective_wbgt:.1f}¬∞C\")\n",
        "    else:\n",
        "        print(\"   üí° Insight: A distinct cooler detour exists.\")\n",
        "        add_route(r1, simplekml.Color.red, \"‚ö° Fastest Route (Exposed)\",\n",
        "                  f\"<b>Direct Path</b><br>Shortest time, but higher heat exposure.<br>Temp: {effective_wbgt:.1f}¬∞C\")\n",
        "        add_route(r2, simplekml.Color.green, \"üåø Cool Route (Shaded)\",\n",
        "                  f\"<b>Shaded Detour</b><br>Maximized tree canopy coverage.<br>Lower heat stress.<br>Temp: {effective_wbgt:.1f}¬∞C\")\n",
        "\n",
        "    # --- AMENITIES SECTION ---\n",
        "    from shapely.geometry import Point, LineString\n",
        "\n",
        "    cool_route_coords = []\n",
        "    for u, v in zip(r2[:-1], r2[1:]):\n",
        "        d = graph.get_edge_data(u, v)[0]\n",
        "        if 'geometry' in d:\n",
        "            xs, ys = d['geometry'].xy\n",
        "            cool_route_coords.extend(list(zip(xs, ys)))\n",
        "        else:\n",
        "            cool_route_coords.append((graph.nodes[u]['x'], graph.nodes[u]['y']))\n",
        "            cool_route_coords.append((graph.nodes[v]['x'], graph.nodes[v]['y']))\n",
        "\n",
        "    route_geom = LineString(cool_route_coords)\n",
        "\n",
        "    count_amenities = 0\n",
        "    if amenities:\n",
        "        for name, lat, lon, type_label in amenities:\n",
        "            poi_point = Point(lon, lat)\n",
        "            if route_geom.distance(poi_point) < 0.003:\n",
        "                p = kml.newpoint(name=f\"{type_label}: {name}\", coords=[(lon, lat)])\n",
        "\n",
        "                if type_label == \"Hawker\":\n",
        "                    p.style.iconstyle.icon.href = 'http://googleusercontent.com/maps.google.com/mapfiles/kml/shapes/dining.png'\n",
        "                    p.description = \"<b>Hawker Centre</b><br>Cheap food & shelter.\"\n",
        "                else:\n",
        "                    p.style.iconstyle.icon.href = 'http://googleusercontent.com/maps.google.com/mapfiles/kml/shapes/grocery.png'\n",
        "                    p.description = \"<b>Supermarket</b><br>Water & supplies.\"\n",
        "\n",
        "                count_amenities += 1\n",
        "\n",
        "    print(f\"   üç± Added {count_amenities} amenities near the route.\")\n",
        "\n",
        "    # 6. SAVE\n",
        "    if not os.path.exists('output'): os.makedirs('output')\n",
        "    constant_filename = \"output/latest_route.kml\"\n",
        "    kml.save(constant_filename)\n",
        "\n",
        "    print(f\"\\nüéâ SUCCESS! Download '{constant_filename}'\")\n",
        "else:\n",
        "    print(\"‚ùå Critical Error: Route Generation Failed.\")\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' --> Uncomment when required\n",
        "\n",
        "# ==========================================\n",
        "# üì§ MODULE 6: CLOUD SYNC (V6.1 - SMART FIX)\n",
        "# ==========================================\n",
        "def push_to_github(filename):\n",
        "    print(\"\\n‚òÅÔ∏è INITIATING CLOUD SYNC...\")\n",
        "\n",
        "    # 1. RETRIEVE TOKEN\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        token = userdata.get('GITHUB_TOKEN')\n",
        "    except:\n",
        "        token = input(\"   Enter GitHub PAT (Token): \")\n",
        "\n",
        "    if not token:\n",
        "        print(\"   ‚ùå Sync Failed: No Token provided.\")\n",
        "        return\n",
        "\n",
        "    # 2. SETUP\n",
        "    repo_url = f\"https://{token}@github.com/{GITHUB_USER}/{REPO_NAME}.git\"\n",
        "    user_email = \"coolride.bot@gmail.com\"\n",
        "    user_name = \"CoolRide Bot\"\n",
        "\n",
        "    # 3. SMART COMMANDS (Auto-detects branch + Creates folder)\n",
        "    import subprocess\n",
        "\n",
        "    # Helper to run commands safely\n",
        "    def run_git(cmd):\n",
        "        try:\n",
        "            # We filter out the token from errors so it doesn't leak in logs\n",
        "            result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)\n",
        "            return True, result.stdout\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            error_msg = e.stderr.replace(token, \"HIDDEN_TOKEN\") # Safety mask\n",
        "            print(f\"   ‚ö†Ô∏è Git Error: {error_msg}\")\n",
        "            return False, error_msg\n",
        "\n",
        "    print(\"   ‚è≥ Cloning repository...\")\n",
        "    run_git(f\"rm -rf temp_repo\") # Clean start\n",
        "    success, _ = run_git(f\"git clone {repo_url} temp_repo\")\n",
        "\n",
        "    if not success: return\n",
        "\n",
        "    print(\"   ‚è≥ Processing files...\")\n",
        "    # Smart Move: Ensure folder exists, Copy file, Configure Git, Push to HEAD (Current Branch)\n",
        "    commands = [\n",
        "        f\"mkdir -p temp_repo/output\", # Force create folder\n",
        "        f\"cp {filename} temp_repo/output/latest_route.kml\",\n",
        "        f\"cp {filename} temp_repo/output/{os.path.basename(filename)}\",\n",
        "        f\"cd temp_repo && git config user.email '{user_email}'\",\n",
        "        f\"cd temp_repo && git config user.name '{user_name}'\",\n",
        "        \"cd temp_repo && git add .\",\n",
        "        f\"cd temp_repo && git commit -m 'ü§ñ AI Update: {time.strftime('%H:%M')}'\",\n",
        "        \"cd temp_repo && git push origin HEAD\" # Pushes to whatever branch (main/master) is active\n",
        "    ]\n",
        "\n",
        "    for cmd in commands:\n",
        "        success, _ = run_git(cmd)\n",
        "        if not success:\n",
        "            print(\"   ‚ùå Sync Aborted due to error above.\")\n",
        "            return\n",
        "\n",
        "    print(\"   ‚úÖ CLOUD SYNC COMPLETE.\")\n",
        "    print(f\"   üåê View: https://github.com/{GITHUB_USER}/{REPO_NAME}/blob/master/output/latest_route.kml\")\n",
        "\n",
        "# EXECUTE\n",
        "if 'constant_filename' in locals():\n",
        "    push_to_github(constant_filename)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YoBJ1pZbb_x_",
        "outputId": "49949ce1-4f96-4748-dd54-b6040a7d2a86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' --> Uncomment when required\\n\\n# ==========================================\\n# üì§ MODULE 6: CLOUD SYNC (V6.1 - SMART FIX)\\n# ==========================================\\ndef push_to_github(filename):\\n    print(\"\\n‚òÅÔ∏è INITIATING CLOUD SYNC...\")\\n\\n    # 1. RETRIEVE TOKEN\\n    try:\\n        from google.colab import userdata\\n        token = userdata.get(\\'GITHUB_TOKEN\\')\\n    except:\\n        token = input(\"   Enter GitHub PAT (Token): \")\\n\\n    if not token:\\n        print(\"   ‚ùå Sync Failed: No Token provided.\")\\n        return\\n\\n    # 2. SETUP\\n    repo_url = f\"https://{token}@github.com/{GITHUB_USER}/{REPO_NAME}.git\"\\n    user_email = \"coolride.bot@gmail.com\"\\n    user_name = \"CoolRide Bot\"\\n\\n    # 3. SMART COMMANDS (Auto-detects branch + Creates folder)\\n    import subprocess\\n\\n    # Helper to run commands safely\\n    def run_git(cmd):\\n        try:\\n            # We filter out the token from errors so it doesn\\'t leak in logs\\n            result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)\\n            return True, result.stdout\\n        except subprocess.CalledProcessError as e:\\n            error_msg = e.stderr.replace(token, \"HIDDEN_TOKEN\") # Safety mask\\n            print(f\"   ‚ö†Ô∏è Git Error: {error_msg}\")\\n            return False, error_msg\\n\\n    print(\"   ‚è≥ Cloning repository...\")\\n    run_git(f\"rm -rf temp_repo\") # Clean start\\n    success, _ = run_git(f\"git clone {repo_url} temp_repo\")\\n\\n    if not success: return\\n\\n    print(\"   ‚è≥ Processing files...\")\\n    # Smart Move: Ensure folder exists, Copy file, Configure Git, Push to HEAD (Current Branch)\\n    commands = [\\n        f\"mkdir -p temp_repo/output\", # Force create folder\\n        f\"cp {filename} temp_repo/output/latest_route.kml\",\\n        f\"cp {filename} temp_repo/output/{os.path.basename(filename)}\",\\n        f\"cd temp_repo && git config user.email \\'{user_email}\\'\",\\n        f\"cd temp_repo && git config user.name \\'{user_name}\\'\",\\n        \"cd temp_repo && git add .\",\\n        f\"cd temp_repo && git commit -m \\'ü§ñ AI Update: {time.strftime(\\'%H:%M\\')}\\'\",\\n        \"cd temp_repo && git push origin HEAD\" # Pushes to whatever branch (main/master) is active\\n    ]\\n\\n    for cmd in commands:\\n        success, _ = run_git(cmd)\\n        if not success:\\n            print(\"   ‚ùå Sync Aborted due to error above.\")\\n            return\\n\\n    print(\"   ‚úÖ CLOUD SYNC COMPLETE.\")\\n    print(f\"   üåê View: https://github.com/{GITHUB_USER}/{REPO_NAME}/blob/master/output/latest_route.kml\")\\n\\n# EXECUTE\\nif \\'constant_filename\\' in locals():\\n    push_to_github(constant_filename)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Live Engine Module (Module 7)"
      ],
      "metadata": {
        "id": "V-yMc_daH0nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# üåê MODULE 7: LIVE API SERVER (V9.7 - MARKERS & TOGGLES)\n",
        "# ==========================================\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "import osmnx as ox\n",
        "import networkx as nx\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "import simplekml\n",
        "import time\n",
        "from shapely.geometry import Point, LineString\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# üîë AUTHENTICATION\n",
        "# ---------------------------------------------------------\n",
        "ngrok.set_auth_token(\"36uk5sD1Xy2OufMem31eLZ9tXLh_7zWriMUTYH9WUGNTgciyG\")\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/calculate_route', methods=['POST'])\n",
        "def handle_route_request():\n",
        "    start_timer = time.time()\n",
        "    global START_POINT, END_POINT, DEPARTURE_TIME, PLACE_NAME\n",
        "\n",
        "    try:\n",
        "        data = request.json\n",
        "        print(f\"\\nüì® NEW REQUEST: {data}\")\n",
        "\n",
        "        start_text = data.get('start', 'Tampines MRT')\n",
        "        end_text = data.get('end', 'Tampines Eco Green')\n",
        "        stop_text = data.get('stop', '')\n",
        "        time_text = data.get('time', '')\n",
        "\n",
        "        PLACE_NAME = f\"{start_text} to {end_text}\"\n",
        "\n",
        "        # 1. Geocode\n",
        "        try:\n",
        "            START_POINT = ox.geocode(start_text + \", Singapore\")\n",
        "            END_POINT = ox.geocode(end_text + \", Singapore\")\n",
        "            STOP_POINT = None\n",
        "            if stop_text:\n",
        "                if \",\" in stop_text:\n",
        "                    lat, lon = map(float, stop_text.split(\",\"))\n",
        "                    STOP_POINT = (lat, lon)\n",
        "                else:\n",
        "                    STOP_POINT = ox.geocode(stop_text + \", Singapore\")\n",
        "        except:\n",
        "            return jsonify({\"status\": \"error\", \"message\": \"Location not found.\"}), 400\n",
        "\n",
        "        # 2. Time Handling\n",
        "        sgt_zone = pytz.timezone('Asia/Singapore')\n",
        "        if not time_text:\n",
        "            DEPARTURE_TIME = datetime.now(sgt_zone)\n",
        "        else:\n",
        "            try:\n",
        "                hour, minute = map(int, time_text.split(':'))\n",
        "                DEPARTURE_TIME = datetime.now(sgt_zone).replace(hour=hour, minute=minute, second=0)\n",
        "            except:\n",
        "                DEPARTURE_TIME = datetime.now(sgt_zone)\n",
        "\n",
        "        # 3. Engine\n",
        "        print(f\"   ‚öôÔ∏è Running AI Engine for: {PLACE_NAME}...\")\n",
        "        graph, _, _, amenities = generate_cool_routes()\n",
        "        if graph is None: return jsonify({\"status\": \"error\", \"message\": \"Graph failed.\"}), 500\n",
        "\n",
        "        # Solver Helper\n",
        "        def solve_path(start_node, end_node):\n",
        "            try:\n",
        "                r_fast = nx.shortest_path(graph, start_node, end_node, weight='length')\n",
        "                r_cool = nx.shortest_path(graph, start_node, end_node, weight='cool_cost')\n",
        "                return r_fast, r_cool\n",
        "            except:\n",
        "                return [], []\n",
        "\n",
        "        orig_node = ox.distance.nearest_nodes(graph, START_POINT[1], START_POINT[0])\n",
        "        dest_node = ox.distance.nearest_nodes(graph, END_POINT[1], END_POINT[0])\n",
        "\n",
        "        # 4. PATH SOLVING\n",
        "        if STOP_POINT:\n",
        "            stop_node = ox.distance.nearest_nodes(graph, STOP_POINT[1], STOP_POINT[0])\n",
        "            l1_fast, l1_cool = solve_path(orig_node, stop_node)\n",
        "            l2_fast, l2_cool = solve_path(stop_node, dest_node)\n",
        "            if l1_fast and l2_fast:\n",
        "                r1 = l1_fast[:-1] + l2_fast\n",
        "                r2 = l1_cool[:-1] + l2_cool\n",
        "            else:\n",
        "                r1, r2 = [], []\n",
        "        else:\n",
        "            r1, r2 = solve_path(orig_node, dest_node)\n",
        "\n",
        "        if not r1: return jsonify({\"status\": \"error\", \"message\": \"No path found.\"}), 500\n",
        "\n",
        "        # --- SMART ANALYTICS ---\n",
        "        def analyze_route(route):\n",
        "            total_len = 0\n",
        "            shaded_len = 0\n",
        "            for u, v in zip(route[:-1], route[1:]):\n",
        "                data = graph.get_edge_data(u, v)[0]\n",
        "                length = data['length']\n",
        "                total_len += length\n",
        "                if data['cool_cost'] < (length * 0.9):\n",
        "                    shaded_len += length\n",
        "\n",
        "            eta_mins = int(total_len / 250)\n",
        "            shade_pct = int((shaded_len / total_len) * 100) if total_len > 0 else 0\n",
        "            return eta_mins, shade_pct\n",
        "\n",
        "        fast_eta, fast_shade = analyze_route(r1)\n",
        "        cool_eta, cool_shade = analyze_route(r2)\n",
        "        shade_gain = cool_shade - fast_shade\n",
        "\n",
        "        # --- AI FORECAST ---\n",
        "        current_wbgt, station_name = get_nearest_wbgt_station(START_POINT[0], START_POINT[1])\n",
        "        ride_hour = DEPARTURE_TIME.hour\n",
        "        forecast_wbgt, heat_offset = predict_smart_wbgt(current_wbgt, ride_hour)\n",
        "\n",
        "        if shade_gain > 20:\n",
        "            insight = f\"<b>Smart Choice:</b> The Cool Route provides <b>{shade_gain}% more shade coverage</b>, effectively reducing solar heat load by ~{shade_gain/10:.1f}¬∞C.\"\n",
        "            status_color = \"green\"\n",
        "        elif heat_offset > 1.0:\n",
        "            insight = f\"<b>Heat Alert:</b> It is {heat_offset:.1f}¬∞C hotter than average. Avoid the exposed Fastest Route.\"\n",
        "            status_color = \"red\"\n",
        "        else:\n",
        "            insight = \"Conditions are mild. Both routes are acceptable, but Green is more scenic.\"\n",
        "            status_color = \"green\"\n",
        "\n",
        "        # 5. Generate KML\n",
        "        kml = simplekml.Kml()\n",
        "\n",
        "        def add_kml_line(route, color, name, desc):\n",
        "            ls = kml.newlinestring(name=name)\n",
        "            coords = []\n",
        "            for u, v in zip(route[:-1], route[1:]):\n",
        "                d = graph.get_edge_data(u, v)[0]\n",
        "                if 'geometry' in d:\n",
        "                    xs, ys = d['geometry'].xy\n",
        "                    coords.extend([(float(x), float(y)) for x, y in zip(xs, ys)])\n",
        "                else:\n",
        "                    coords.append((float(graph.nodes[u]['x']), float(graph.nodes[u]['y'])))\n",
        "                    coords.append((float(graph.nodes[v]['x']), float(graph.nodes[v]['y'])))\n",
        "            ls.coords = coords\n",
        "            ls.style.linestyle.color = color\n",
        "            ls.style.linestyle.width = 5\n",
        "            ls.description = desc\n",
        "            return ls, coords\n",
        "\n",
        "        desc_fast = f\"\"\"\n",
        "        <div style='font-family:sans-serif; width:200px;'>\n",
        "            <h3 style='margin:0;color:#ef4444;'>‚ö° Fastest Route</h3>\n",
        "            <p style='margin:5px 0;'><b>{fast_eta} mins</b> ‚Ä¢ {fast_shade}% Shaded</p>\n",
        "            <p style='font-size:11px;color:#64748b;'>High solar exposure. Not recommended during midday.</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        desc_cool = f\"\"\"\n",
        "        <div style='font-family:sans-serif; width:200px;'>\n",
        "            <h3 style='margin:0;color:#22c55e;'>üåø Cool Route</h3>\n",
        "            <p style='margin:5px 0;'><b>{cool_eta} mins</b> ‚Ä¢ {cool_shade}% Shaded</p>\n",
        "            <p style='font-size:11px;color:#64748b;'>Optimized for tree canopy & building shadows.</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        add_kml_line(r1, simplekml.Color.red, \"Fastest Route\", desc_fast)\n",
        "        _, cool_coords = add_kml_line(r2, simplekml.Color.green, \"Cool Route\", desc_cool)\n",
        "\n",
        "        # 6. Amenities\n",
        "        route_geom = LineString(cool_coords)\n",
        "        count = 0\n",
        "        for name, lat, lon, type_label in amenities:\n",
        "            lat, lon = float(lat), float(lon)\n",
        "            poi_point = Point(lon, lat)\n",
        "            if route_geom.distance(poi_point) < 0.003:\n",
        "                emoji = \"üçú\" if type_label == \"Hawker\" else \"üõí\"\n",
        "                p = kml.newpoint(name=f\"{emoji} {name}\")\n",
        "                p.coords = [(lon, lat)]\n",
        "                safe_name = name.replace(\"'\", \"\").replace('\"', \"\")\n",
        "                p.description = f\"\"\"\n",
        "                <b>{type_label}</b><br>{name}<br><br>\n",
        "                <button onclick=\"parent.addStop('{lat},{lon}', '{safe_name}')\"\n",
        "                style=\"background:#2563eb;color:white;border:none;padding:5px 10px;cursor:pointer;border-radius:4px;\">\n",
        "                ‚ûï Add Stop Here\n",
        "                </button>\n",
        "                \"\"\"\n",
        "                count += 1\n",
        "\n",
        "        duration = time.time() - start_timer\n",
        "        print(f\"‚è±Ô∏è Generation Time: {duration:.2f}s\")\n",
        "\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"kml_data\": kml.kml(),\n",
        "            \"meta\": {\n",
        "                \"duration\": f\"{duration:.2f}s\",\n",
        "                \"start_point\": START_POINT, # SEND START COORDS\n",
        "                \"end_point\": END_POINT      # SEND END COORDS\n",
        "            },\n",
        "            \"ai_data\": {\n",
        "                \"current_temp\": f\"{current_wbgt:.1f}\",\n",
        "                \"forecast_temp\": f\"{forecast_wbgt:.1f}\",\n",
        "                \"insight\": insight,\n",
        "                \"color\": status_color,\n",
        "                \"shade_gain\": shade_gain\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Server Error Traceback: {e}\")\n",
        "        return jsonify({\"status\": \"error\", \"message\": str(e)}), 500\n",
        "\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\"üöÄ SERVER ONLINE! API URL: {public_url}\")\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipj_PEDnirnQ",
        "outputId": "f959fffb-3543-4177-9c98-8493273a40a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ SERVER ONLINE! API URL: https://neurally-submucronate-sonny.ngrok-free.dev\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2025 12:45:45] \"OPTIONS /calculate_route HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì® NEW REQUEST: {'start': 'Tampines MRT', 'end': 'Tampines Eco Green', 'time': '14:00', 'stop': ''}\n",
            "   ‚öôÔ∏è Running AI Engine for: Tampines MRT to Tampines Eco Green...\n",
            "‚è≥ Downloading road network for Tampines MRT to Tampines Eco Green...\n",
            "   üåç Source: OpenStreetMap.fr (Backup Mirror)\n",
            "   üìê Zone: Lat[1.3430, 1.3737], Lon[103.9354, 103.9582]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [24/Dec/2025 12:46:51] \"\u001b[35m\u001b[1mPOST /calculate_route HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚ö†Ô∏è Primary Download Failed: HTTPSConnectionPool(host='api.openstreetmap.fr', port=443): Max retries exceeded with url: /oapi/interpreter/interpreter (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x78cbc526bef0>: Failed to resolve 'api.openstreetmap.fr' ([Errno -2] Name or service not known)\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-12-24T12:54:28+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-f5fa27df-d875-4667-84df-c8e1aa3b6eef acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-12-24T12:54:28+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-5000-f5fa27df-d875-4667-84df-c8e1aa3b6eef err=\"failed to start tunnel: session closed\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}