{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swaminaathakrishnan/Cool_Route_prototype/blob/master/Cool_route_v5.3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEQqXNM0C1M6"
      },
      "source": [
        "# üö¥ **CoolRide V5.2: User Input Edition**\n",
        "### Project Overview\n",
        "\n",
        "CoolRide V5.2 adds **user input** for custom routes!\n",
        "\n",
        "**New in V5.2:**\n",
        "- üìç User input for starting point (latitude, longitude)\n",
        "- üéØ User input for ending point (latitude, longitude)\n",
        "- ‚è∞ Optional time input (defaults to current time if not provided)\n",
        "- üé® Interactive route customization\n",
        "\n",
        "**Features from V5:**\n",
        "- üíß Water body cooling effects (evaporative + convective cooling)\n",
        "- üåä 100m buffer zone for water-adjacent routes\n",
        "- üìè Size-based filtering (excludes tiny ponds <0.1 km¬≤)\n",
        "- üéØ 45% cost reduction for water-adjacent paths\n",
        "- üè¢ Building shadow calculation using sun position\n",
        "- ‚è∞ Time-aware routing (different routes at different times of day)\n",
        "- üå°Ô∏è Combined tree + building shade analysis\n",
        "\n",
        "CoolRide is a TRL-6 prototype designed to route cyclists through thermally comfortable paths in Singapore. It utilizes real-time government weather data (NEA), building shadows, vegetation data, water bodies, and predictive AI to mitigate Urban Heat Island (UHI) effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0EGg6-lCtkh",
        "outputId": "a8bdc668-cb85-4d3c-f47a-d971b81aa985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/53.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for simplekml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "‚úÖ System Initialized. Ready for V5 Execution.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# üß± MODULE 1: SYSTEM INITIALIZATION\n",
        "# ==========================================\n",
        "# Objective: Install geospatial libraries and set up the environment.\n",
        "# dependencies: OSMnx (Maps), GeoPandas (Spatial Data), Scikit-Learn (AI).\n",
        "\n",
        "!pip install osmnx simplekml geopandas shapely networkx requests scikit-learn -q\n",
        "\n",
        "import osmnx as ox\n",
        "import networkx as nx\n",
        "import simplekml\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from shapely.geometry import Point, LineString, box\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "print(\"‚úÖ System Initialized. Ready for V5 Execution.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAdgf4rmDPgv"
      },
      "source": [
        "### ‚öôÔ∏è Module 2: Configuration & Cloud Connection\n",
        "Objective: Define the pilot zone and connect to the GitHub Data Lake. Logic: Instead of local files, we stream GeoJSON/CSV directly from the raw GitHub URLs. This allows the team to collaborate without sharing Drive folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTJjWFUyDNOX",
        "outputId": "e013bdef-bd84-4210-f47b-66b5c265d278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üö¥ COOLRIDE V5.3 - PRODUCTION ENGINE\n",
            "==================================================\n",
            "   üìç Route: Tampines MRT to Tampines Eco Green\n",
            "   üïê Departure Time (SGT): 02:00 PM\n",
            "      (Sun position calculated for: 2025-12-23 14:00:00.132865+08:00)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# ‚öôÔ∏è MODULE 2: CONFIGURATION (V5.3 - AUTOMATION READY)\n",
        "# ==========================================\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üö¥ COOLRIDE V5.3 - PRODUCTION ENGINE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. ROUTE PARAMETERS (Bridge Variables)\n",
        "# Ziyi's App can overwrite these lines automatically before execution.\n",
        "# Default: Tampines Loop\n",
        "START_NAME = \"Tampines MRT\"\n",
        "START_COORDS = (1.3533, 103.9452)\n",
        "\n",
        "END_NAME = \"Tampines Eco Green\"\n",
        "END_COORDS = (1.3598, 103.9351)\n",
        "\n",
        "# 2. TIME CONFIGURATION (CRITICAL FIX: UTC+8)\n",
        "# We force the timezone to Asia/Singapore so shadows are accurate.\n",
        "sgt_zone = pytz.timezone('Asia/Singapore')\n",
        "current_time_sgt = datetime.now(sgt_zone)\n",
        "\n",
        "# Manual Override for Demo (Optional)\n",
        "# DEPARTURE_TIME = current_time_sgt.replace(hour=14, minute=0)\n",
        "\n",
        "# Force 2:00 PM today for shadow simulation\n",
        "DEPARTURE_TIME = current_time_sgt.replace(hour=14, minute=0, second=0)\n",
        "# DEPARTURE_TIME = current_time_sgt\n",
        "\n",
        "PLACE_NAME = f\"{START_NAME} to {END_NAME}\"\n",
        "START_POINT = START_COORDS\n",
        "END_POINT = END_COORDS\n",
        "\n",
        "print(f\"   üìç Route: {PLACE_NAME}\")\n",
        "print(f\"   üïê Departure Time (SGT): {DEPARTURE_TIME.strftime('%I:%M %p')}\")\n",
        "print(f\"      (Sun position calculated for: {DEPARTURE_TIME})\")\n",
        "\n",
        "# 3. GITHUB DATA LAKE\n",
        "GITHUB_USER = \"swaminaathakrishnan\"\n",
        "REPO_NAME = \"Cool_Route_prototype\"\n",
        "BASE_URL = f\"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/master/data/\"\n",
        "\n",
        "# File Links\n",
        "PCN_URL = BASE_URL + \"ParkConnectorLoop.geojson\"\n",
        "HAWKER_URL = BASE_URL + \"HawkerCentresGEOJSON.geojson\"\n",
        "TREES_URL = BASE_URL + \"trees.csv\"\n",
        "WATER_URL = BASE_URL + \"water.geojson\"\n",
        "\n",
        "# 4. THERMAL WEIGHTS\n",
        "WEIGHT_PCN = 0.5\n",
        "WEIGHT_WATER = 0.55\n",
        "WEIGHT_TREE_SHADE = 0.6\n",
        "WEIGHT_BUILDING_SHADE = 0.7\n",
        "WEIGHT_ULTIMATE = 0.35 # All factors combined\n",
        "\n",
        "# 5. WATER PARAMETERS\n",
        "WATER_BUFFER_DISTANCE = 100\n",
        "MIN_WATER_SIZE = 50000\n",
        "\n",
        "# 6. SAFETY OVERRIDE\n",
        "NEA_HEATWAVE_ALERT = False\n",
        "\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15vvFycdD22Q"
      },
      "source": [
        "### Module 3A: Sun Position & Building Shadow Engine\n",
        "\n",
        "\n",
        "Objective: Calculate real-time building shadows based on sun position and building heights.\n",
        "\n",
        "**Physics:**\n",
        "- Sun elevation angle determines shadow length\n",
        "- Shadow direction is opposite of sun azimuth\n",
        "- Taller buildings cast longer shadows (especially at low sun angles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6ZIZQoLUCpnU",
        "outputId": "90032508-67a0-4eb0-ae47-79f8007dc448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Position & Building Shadow Functions Loaded\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# MODULE 3A: SUN POSITION & BUILDING SHADOWS (V4)\n",
        "\n",
        "def calculate_sun_position(latitude, longitude, timestamp):\n",
        "    \"\"\"\n",
        "    Calculate sun elevation and azimuth for given location and time\n",
        "\n",
        "    Returns: (elevation_degrees, azimuth_degrees)\n",
        "    \"\"\"\n",
        "    import math\n",
        "    day_of_year = timestamp.timetuple().tm_yday\n",
        "\n",
        "    # Declination angle\n",
        "    declination = 23.45 * math.sin(math.radians((360/365) * (day_of_year - 81)))\n",
        "\n",
        "    # Hour angle\n",
        "    hour = timestamp.hour + timestamp.minute / 60.0\n",
        "    hour_angle = 15 * (hour - 12)\n",
        "\n",
        "    # Sun elevation\n",
        "    lat_rad = math.radians(latitude)\n",
        "    dec_rad = math.radians(declination)\n",
        "    ha_rad = math.radians(hour_angle)\n",
        "\n",
        "    sin_elev = (math.sin(lat_rad) * math.sin(dec_rad) +\n",
        "                math.cos(lat_rad) * math.cos(dec_rad) * math.cos(ha_rad))\n",
        "    elevation = math.degrees(math.asin(max(-1, min(1, sin_elev))))\n",
        "\n",
        "    # Sun azimuth\n",
        "    cos_azim = ((math.sin(dec_rad) - math.sin(lat_rad) * sin_elev) /\n",
        "                (math.cos(lat_rad) * math.cos(math.radians(elevation))))\n",
        "    cos_azim = max(-1, min(1, cos_azim))\n",
        "    azimuth = math.degrees(math.acos(cos_azim))\n",
        "\n",
        "    if hour > 12:\n",
        "        azimuth = 360 - azimuth\n",
        "\n",
        "    return elevation, azimuth\n",
        "\n",
        "\n",
        "def create_shadow_polygon(building_polygon, building_height, sun_elevation, sun_azimuth):\n",
        "    \"\"\"\n",
        "    Create shadow polygon from building footprint\n",
        "\n",
        "    Args:\n",
        "        building_polygon: Shapely Polygon\n",
        "        building_height: Height in meters\n",
        "        sun_elevation: Sun angle above horizon (degrees)\n",
        "        sun_azimuth: Sun compass direction (degrees)\n",
        "\n",
        "    Returns:\n",
        "        Shadow polygon (Shapely)\n",
        "    \"\"\"\n",
        "    import math\n",
        "    from shapely.affinity import translate\n",
        "\n",
        "    if sun_elevation <= 0:\n",
        "        return None  # Night time\n",
        "\n",
        "    # Shadow length = height / tan(elevation)\n",
        "    shadow_length = building_height / math.tan(math.radians(sun_elevation))\n",
        "\n",
        "    # Shadow direction (opposite of sun)\n",
        "    shadow_direction = (sun_azimuth + 180) % 360\n",
        "\n",
        "    # Calculate offset in meters\n",
        "    shadow_offset_y = shadow_length * math.cos(math.radians(shadow_direction))\n",
        "    shadow_offset_x = shadow_length * math.sin(math.radians(shadow_direction))\n",
        "\n",
        "    # Get building centroid\n",
        "    centroid = building_polygon.centroid\n",
        "    lat, lon = centroid.y, centroid.x\n",
        "\n",
        "    # Convert meters to degrees\n",
        "    deg_per_meter_lat = 1 / 111000\n",
        "    deg_per_meter_lon = 1 / (111000 * math.cos(math.radians(lat)))\n",
        "\n",
        "    offset_lat = shadow_offset_y * deg_per_meter_lat\n",
        "    offset_lon = shadow_offset_x * deg_per_meter_lon\n",
        "\n",
        "    # Create shadow by translating building polygon\n",
        "    shadow = translate(building_polygon, xoff=offset_lon, yoff=offset_lat)\n",
        "\n",
        "    # Union with building for full coverage\n",
        "    full_shadow = building_polygon.union(shadow).convex_hull\n",
        "\n",
        "    return full_shadow\n",
        "\n",
        "print(\"Sun Position & Building Shadow Functions Loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shjrIqRbCpnV"
      },
      "source": [
        "### Module 3B: Enhanced Spatial Graph Engine\n",
        "\n",
        "Objective: Build road network and overlay ALL cooling features.\n",
        "\n",
        "**Layer 1:** Road Network (OSM)  \n",
        "**Layer 2:** Park Connectors (PCN)  \n",
        "**Layer 3:** Tree Canopy (SGTrees)  \n",
        "**Layer 4:** Building Shadows (Time-dependent)  \n",
        "**Layer 5:** Water Bodies (NEW in V5! - Proximity-based cooling)\n",
        "\n",
        "Logic: Roads receive cumulative discounts based on shade coverage from multiple sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lORoECPKEX2a"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# üó∫Ô∏è MODULE 3B: ENHANCED SPATIAL GRAPH ENGINE (V5.4 - ROBUST WATER)\n",
        "# ==========================================\n",
        "\n",
        "def generate_cool_routes():\n",
        "    print(f\"‚è≥ Downloading road network for {PLACE_NAME}...\")\n",
        "\n",
        "    # 1. GET GRAPH\n",
        "    try:\n",
        "        G = ox.graph_from_point(START_POINT, dist=2000, network_type='bike')\n",
        "        nodes = ox.graph_to_gdfs(G, edges=False)\n",
        "        miny, maxy = nodes.y.min(), nodes.y.max()\n",
        "        minx, maxx = nodes.x.min(), nodes.x.max()\n",
        "        print(f\"   üìê Zone Limits: Lat[{miny:.4f}, {maxy:.4f}], Lon[{minx:.4f}, {maxx:.4f}]\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Network Error: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    # 2. LOAD PCN\n",
        "    print(\"‚è≥ Overlaying Park Connectors...\")\n",
        "    pcn_union = None\n",
        "    try:\n",
        "        pcn_data = gpd.read_file(PCN_URL)\n",
        "        if pcn_data.crs != \"EPSG:4326\": pcn_data = pcn_data.to_crs(\"EPSG:4326\")\n",
        "        try: pcn_union = pcn_data.geometry.union_all()\n",
        "        except: pcn_union = pcn_data.geometry.unary_union\n",
        "        print(f\"   ‚úÖ PCN Loaded\")\n",
        "    except:\n",
        "        print(\"   ‚ö†Ô∏è PCN Data missing (Proceeding without it)\")\n",
        "\n",
        "    # 3. LOAD TREES\n",
        "    print(\"‚è≥ Loading Tree Canopy Data...\")\n",
        "    trees_buffer = None\n",
        "    try:\n",
        "        local_file = \"trees_downloaded.csv\"\n",
        "        if not os.path.exists(local_file):\n",
        "            lfs_url = f\"https://github.com/{GITHUB_USER}/{REPO_NAME}/raw/master/data/trees.csv\"\n",
        "            os.system(f\"wget -O {local_file} {lfs_url}\")\n",
        "\n",
        "        trees_df = pd.read_csv(local_file)\n",
        "        trees_df.columns = [c.lower() for c in trees_df.columns]\n",
        "        lat_col = 'latitude' if 'latitude' in trees_df.columns else 'lat'\n",
        "        lng_col = 'longitude' if 'longitude' in trees_df.columns else 'lng'\n",
        "\n",
        "        trees_df = trees_df[\n",
        "            (trees_df[lat_col] >= miny) & (trees_df[lat_col] <= maxy) &\n",
        "            (trees_df[lng_col] >= minx) & (trees_df[lng_col] <= maxx)\n",
        "        ]\n",
        "\n",
        "        if len(trees_df) > 0:\n",
        "            geometry = [Point(xy) for xy in zip(trees_df[lng_col], trees_df[lat_col])]\n",
        "            trees_gdf = gpd.GeoDataFrame(trees_df, geometry=geometry, crs=\"EPSG:4326\")\n",
        "            trees_buffer = trees_gdf.geometry.buffer(0.0001).unary_union\n",
        "            print(f\"   ‚úÖ Tree shade layer generated ({len(trees_df)} trees)\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Tree Data Error: {e}\")\n",
        "\n",
        "    # 4. LOAD BUILDINGS (With SGT Time)\n",
        "    print(\"‚è≥ Loading Buildings...\")\n",
        "    building_shadows = None\n",
        "    try:\n",
        "        buildings_gdf = ox.features_from_point(START_POINT, tags={'building': True}, dist=2000)\n",
        "        buildings_gdf = buildings_gdf[buildings_gdf.geometry.type == 'Polygon']\n",
        "\n",
        "        # Height Logic\n",
        "        buildings_gdf['estimated_height'] = 15\n",
        "\n",
        "        # Calculate Sun Position\n",
        "        sun_elev, sun_azim = calculate_sun_position(START_POINT[0], START_POINT[1], DEPARTURE_TIME)\n",
        "\n",
        "        print(f\"   ‚òÄÔ∏è Sun (SGT): {sun_elev:.1f}¬∞ elev, {sun_azim:.1f}¬∞ azim\")\n",
        "\n",
        "        if sun_elev > 0:\n",
        "            shadow_polygons = []\n",
        "            for _, building in buildings_gdf.iterrows():\n",
        "                shadow = create_shadow_polygon(building.geometry, building['estimated_height'], sun_elev, sun_azim)\n",
        "                if shadow: shadow_polygons.append(shadow)\n",
        "\n",
        "            from shapely.ops import unary_union\n",
        "            building_shadows = unary_union(shadow_polygons)\n",
        "            print(f\"   ‚úÖ Building shadow layer generated\")\n",
        "        else:\n",
        "            print(\"   üåô Night time (No shadows)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Building Error: {e}\")\n",
        "\n",
        "    # 5. LOAD WATER BODIES (SPLIT-FETCH STRATEGY)\n",
        "    print(\"‚è≥ Loading Water Bodies...\")\n",
        "    water_buffer = None\n",
        "    water_gdfs = []\n",
        "\n",
        "    # A. Try GitHub Download First\n",
        "    try:\n",
        "        local_water = \"data/water.geojson\"\n",
        "        if not os.path.exists(local_water):\n",
        "             resp = requests.get(WATER_URL, timeout=3)\n",
        "             if resp.status_code == 200:\n",
        "                 with open(local_water, 'wb') as f: f.write(resp.content)\n",
        "                 gdf = gpd.read_file(local_water)\n",
        "                 water_gdfs.append(gdf)\n",
        "                 print(\"   üì• Loaded Water from GitHub\")\n",
        "    except: pass\n",
        "\n",
        "    # B. Fallback to OSM (Split by Tag to prevent total failure)\n",
        "    if not water_gdfs:\n",
        "        print(\"   üåç Fetching Water from OpenStreetMap (Split Strategy)...\")\n",
        "        # We fetch layers separately. If 'canals' crash, we still keep 'lakes'.\n",
        "        tags_to_try = [\n",
        "            {'natural': 'water'},       # Lakes/Reservoirs (Safe)\n",
        "            {'waterway': 'river'},      # Rivers (Medium)\n",
        "            {'waterway': 'canal'}       # Canals (High Risk of NaN errors)\n",
        "        ]\n",
        "\n",
        "        bbox = (maxy, miny, maxx, minx)\n",
        "\n",
        "        for tag in tags_to_try:\n",
        "            try:\n",
        "                gdf = ox.features_from_bbox(bbox=bbox, tags=tag)\n",
        "                if not gdf.empty:\n",
        "                    # Strict Filter: Polygons/Lines only (Remove Points which cause errors)\n",
        "                    gdf = gdf[gdf.geometry.type.isin(['Polygon', 'MultiPolygon', 'LineString', 'MultiLineString'])]\n",
        "                    if not gdf.empty:\n",
        "                        water_gdfs.append(gdf)\n",
        "            except:\n",
        "                continue # If one tag fails, skip it and keep going\n",
        "\n",
        "    # C. Combine & Buffer\n",
        "    if water_gdfs:\n",
        "        try:\n",
        "            # Merge all successful downloads\n",
        "            water_gdf = pd.concat(water_gdfs, ignore_index=True)\n",
        "            if not water_gdf.empty:\n",
        "                if water_gdf.crs != \"EPSG:4326\": water_gdf = water_gdf.to_crs(\"EPSG:4326\")\n",
        "\n",
        "                # Buffer ~100m\n",
        "                water_buffer = water_gdf.geometry.buffer(0.001).unary_union\n",
        "                print(f\"   ‚úÖ Water Cooling Layer Generated ({len(water_gdf)} features)\")\n",
        "            else:\n",
        "                print(\"   ‚ÑπÔ∏è No significant water bodies found (Filtered)\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è Water Merge Error: {e}\")\n",
        "    else:\n",
        "        print(\"   ‚ÑπÔ∏è No water bodies found\")\n",
        "\n",
        "    # 6. CALCULATE COST\n",
        "    print(\"‚è≥ Calculating Costs...\")\n",
        "\n",
        "    # Time-dependent building shade factor\n",
        "    hour = DEPARTURE_TIME.hour\n",
        "    shade_multiplier = 0.6 if (hour < 10 or hour > 16) else 1.0\n",
        "\n",
        "    for u, v, k, data in G.edges(keys=True, data=True):\n",
        "        if 'geometry' in data: edge_geom = data['geometry']\n",
        "        else: edge_geom = LineString([(G.nodes[u]['x'], G.nodes[u]['y']), (G.nodes[v]['x'], G.nodes[v]['y'])])\n",
        "\n",
        "        cost = data['length']\n",
        "        tags = []\n",
        "\n",
        "        # Factors\n",
        "        is_pcn = pcn_union and edge_geom.intersects(pcn_union)\n",
        "        is_tree = trees_buffer and edge_geom.intersects(trees_buffer)\n",
        "        is_shadow = building_shadows and edge_geom.intersects(building_shadows)\n",
        "        is_water = water_buffer and edge_geom.intersects(water_buffer)\n",
        "\n",
        "        # Scoring Logic\n",
        "        if is_tree and is_shadow and is_water:\n",
        "            cost *= WEIGHT_ULTIMATE\n",
        "            tags.append(\"üå≥üè¢üíß Ultimate Cool\")\n",
        "        elif is_tree and is_shadow:\n",
        "            cost *= 0.45\n",
        "            tags.append(\"üå≥üè¢ Tree+Bldg\")\n",
        "        elif is_water:\n",
        "            cost *= WEIGHT_WATER\n",
        "            tags.append(\"üíß Water Breeze\")\n",
        "        elif is_tree:\n",
        "            cost *= WEIGHT_TREE_SHADE\n",
        "            tags.append(\"üå≥ Tree Shade\")\n",
        "        elif is_shadow:\n",
        "            cost *= (WEIGHT_BUILDING_SHADE * shade_multiplier)\n",
        "            tags.append(\"üè¢ Bldg Shadow\")\n",
        "        elif is_pcn:\n",
        "            cost *= WEIGHT_PCN\n",
        "            tags.append(\"üåø PCN\")\n",
        "\n",
        "        data['cool_cost'] = cost\n",
        "        data['tag'] = \" + \".join(tags) if tags else \"‚òÄÔ∏è Exposed\"\n",
        "\n",
        "    # 7. SOLVE\n",
        "    orig = ox.distance.nearest_nodes(G, START_POINT[1], START_POINT[0])\n",
        "    dest = ox.distance.nearest_nodes(G, END_POINT[1], END_POINT[0])\n",
        "\n",
        "    try:\n",
        "        r_fast = nx.shortest_path(G, orig, dest, weight='length')\n",
        "        r_cool = nx.shortest_path(G, orig, dest, weight='cool_cost')\n",
        "        return G, r_fast, r_cool, []\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Routing failed: {e}\")\n",
        "        return None, None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MqM53NLEEZ97"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# üß† MODULE 4: HISTORICAL AI ENGINE (V3)\n",
        "# ==========================================\n",
        "CACHE_FILE = \"coolride_weather_memory.pkl\"\n",
        "\n",
        "def get_cache():\n",
        "    if os.path.exists(CACHE_FILE):\n",
        "        try:\n",
        "            with open(CACHE_FILE, \"rb\") as f: return pickle.load(f)\n",
        "        except: return {}\n",
        "    return {}\n",
        "\n",
        "def save_cache(data):\n",
        "    with open(CACHE_FILE, \"wb\") as f: pickle.dump(data, f)\n",
        "\n",
        "def fetch_historical_data(station_name, days_back=3):\n",
        "    cache = get_cache()\n",
        "    today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    cache_key = f\"{station_name}_{today_str}\"\n",
        "\n",
        "    if cache_key in cache and len(cache[cache_key]['values']) > 20:\n",
        "        print(f\"   ‚ö° Memory Hit! Loaded {len(cache[cache_key]['values'])} points.\")\n",
        "        return cache[cache_key]['timestamps'], cache[cache_key]['values']\n",
        "\n",
        "    print(f\"   üì° Memory Miss. Analyzing last {days_back} days...\")\n",
        "    all_timestamps, all_values = [], []\n",
        "\n",
        "    for i in range(days_back + 1):\n",
        "        target_date = (datetime.now() - timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
        "        url = \"https://api-open.data.gov.sg/v2/real-time/api/weather\"\n",
        "        params = {\"api\": \"wbgt\", \"date\": target_date}\n",
        "\n",
        "        # PAGINATION LOOP\n",
        "        while True:\n",
        "            try:\n",
        "                resp = requests.get(url, params=params, timeout=5)\n",
        "                if resp.status_code != 200: break\n",
        "                data = resp.json()\n",
        "                if 'data' not in data: break\n",
        "\n",
        "                for rec in data['data'].get('records', []):\n",
        "                    dt = datetime.fromisoformat(rec['datetime'])\n",
        "                    for r in rec['item']['readings']:\n",
        "                        if r.get('station', {}).get('name') == station_name:\n",
        "                            val = float(r.get('wbgt') or r.get('value'))\n",
        "                            mins = dt.hour * 60 + dt.minute\n",
        "                            now_mins = datetime.now().hour * 60 + datetime.now().minute\n",
        "                            if abs(mins - now_mins) < 240: # 4 hour window\n",
        "                                all_timestamps.append(mins)\n",
        "                                all_values.append(val)\n",
        "\n",
        "                token = data['data'].get('paginationToken')\n",
        "                if token: params['paginationToken'] = token\n",
        "                else: break\n",
        "            except: break\n",
        "\n",
        "    if len(all_values) > 20:\n",
        "        cache[cache_key] = {'timestamps': all_timestamps, 'values': all_values}\n",
        "        save_cache(cache)\n",
        "        print(f\"   üíæ Learned & Saved {len(all_values)} thermal patterns.\")\n",
        "\n",
        "    return all_timestamps, all_values\n",
        "\n",
        "def predict_trend(station_name, current_wbgt):\n",
        "    timestamps, values = fetch_historical_data(station_name)\n",
        "    if len(values) < 10: return current_wbgt, \"Stable ‚ûñ\", \"Low Data\"\n",
        "\n",
        "    # Linear Regression\n",
        "    model = LinearRegression()\n",
        "    model.fit(np.array(timestamps).reshape(-1, 1), np.array(values))\n",
        "\n",
        "    # Forecast\n",
        "    now = datetime.now()\n",
        "    fut_min = now.hour * 60 + now.minute + 15\n",
        "    raw_pred = model.predict([[fut_min]])[0]\n",
        "\n",
        "    # Physics Clamp\n",
        "    delta = raw_pred - current_wbgt\n",
        "    if abs(delta) > 0.5:\n",
        "        final_pred = current_wbgt + (0.5 if delta > 0 else -0.5)\n",
        "        note = \"(Physics Clamped)\"\n",
        "    else:\n",
        "        final_pred = raw_pred\n",
        "        note = \"\"\n",
        "\n",
        "    trend = \"Rising üìà\" if final_pred > current_wbgt + 0.1 else \"Falling üìâ\" if final_pred < current_wbgt - 0.1 else \"Stable ‚ûñ\"\n",
        "    return final_pred, trend, f\"High {note}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owRqKP4MEvtZ"
      },
      "source": [
        "### üöÄ Module 5: Execution & Safe-Pace Recommendations\n",
        "\n",
        "Objective: Synthesize map, weather, and AI data into a KML route. Upgrade:\n",
        "\n",
        "* Govt Override: Checks NEA_HEATWAVE_ALERT.\n",
        "* Safe Pacing: Suggests specific ride speeds and hydration intervals based on WBGT (ISO 7243 standards)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbhsl3iKExZF",
        "outputId": "d937a4a1-04e2-419b-c04e-990f9d75ff6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ STARTING COOLRIDE ENGINE (WITH ACTIVE AI)...\n",
            "‚è≥ Downloading road network for Tampines MRT to Tampines Eco Green...\n",
            "   üìê Zone Limits: Lat[1.3353, 1.3713], Lon[103.9273, 103.9632]\n",
            "‚è≥ Overlaying Park Connectors...\n",
            "   ‚úÖ PCN Loaded\n",
            "‚è≥ Loading Tree Canopy Data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2525741080.py:53: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  trees_buffer = trees_gdf.geometry.buffer(0.0001).unary_union\n",
            "/tmp/ipython-input-2525741080.py:53: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
            "  trees_buffer = trees_gdf.geometry.buffer(0.0001).unary_union\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚úÖ Tree shade layer generated (29766 trees)\n",
            "‚è≥ Loading Buildings...\n",
            "   ‚òÄÔ∏è Sun (SGT): 51.7¬∞ elev, 227.8¬∞ azim\n",
            "   ‚úÖ Building shadow layer generated\n",
            "‚è≥ Loading Water Bodies...\n",
            "   üåç Fetching Water from OpenStreetMap (Split Strategy)...\n",
            "   ‚ÑπÔ∏è No water bodies found\n",
            "‚è≥ Calculating Costs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/shapely/measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
            "  return lib.area(geometry, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/shapely/measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
            "  return lib.area(geometry, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/shapely/measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
            "  return lib.area(geometry, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Connecting to NEA Official WBGT Sensor Network...\n",
            "   üìç Nearest Sensor: Bedok North Street 2 (Dist: 3.12 km)\n",
            "   ‚ö° Memory Hit! Loaded 128 points.\n",
            "\n",
            "üìä REPORT: Bedok North Street 2\n",
            "   Current: 25.5¬∞C | Forecast: 26.0¬∞C\n",
            "   üîç Route Similarity Score: 93.1%\n",
            "   üí° Insight: Routes are effectively identical (Merged).\n",
            "\n",
            "üéâ SUCCESS! Download 'output/latest_route.kml'\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# üöÄ MODULE 5: EXECUTION ENGINE (V3.9 - FINAL LABELS)\n",
        "# ==========================================\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import simplekml\n",
        "\n",
        "print(\"üöÄ STARTING COOLRIDE ENGINE (WITH ACTIVE AI)...\")\n",
        "\n",
        "# --- HELPER: DYNAMIC SENSOR FINDER (FULL V2 LOGIC) ---\n",
        "def get_nearest_wbgt_station(lat, lon):\n",
        "    print(\"‚è≥ Connecting to NEA Official WBGT Sensor Network...\")\n",
        "    url = \"https://api-open.data.gov.sg/v2/real-time/api/weather\"\n",
        "    try:\n",
        "        resp = requests.get(url, params={\"api\": \"wbgt\"}, timeout=10)\n",
        "        data = resp.json()\n",
        "        readings = data['data']['records'][0]['item'].get('readings', [])\n",
        "\n",
        "        closest_station = \"Unknown\"\n",
        "        min_dist = float('inf')\n",
        "        current_val = None\n",
        "\n",
        "        for r in readings:\n",
        "            try:\n",
        "                loc = {}\n",
        "                s_name = \"Unknown\"\n",
        "                if 'location' in r: loc = r['location']\n",
        "                elif 'station' in r and 'location' in r['station']: loc = r['station']['location']\n",
        "                if 'station' in r: s_name = r['station'].get('name', 'Unknown')\n",
        "                s_lat = float(loc.get('latitude', 0))\n",
        "                s_lon = float(loc.get('longitude', loc.get('longtitude', 0)))\n",
        "                if s_lat == 0 or s_lon == 0: continue\n",
        "\n",
        "                val = r.get('wbgt') or r.get('value')\n",
        "                if val is None: continue\n",
        "                val = float(val)\n",
        "                dist = math.sqrt((lat - s_lat)**2 + (lon - s_lon)**2)\n",
        "\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    closest_station = s_name\n",
        "                    current_val = val\n",
        "            except: continue\n",
        "\n",
        "        if current_val is None: return 30.0, \"System Fallback\"\n",
        "        print(f\"   üìç Nearest Sensor: {closest_station} (Dist: {min_dist*111:.2f} km)\")\n",
        "        return current_val, closest_station\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è WBGT Sensor Fail: {e}. Using Default Safety Value.\")\n",
        "        return 30.0, \"System Fallback\"\n",
        "\n",
        "# 1. GENERATE ROUTES\n",
        "graph, r1, r2, shelters = generate_cool_routes()\n",
        "\n",
        "if graph:\n",
        "    # 2. GET WEATHER\n",
        "    current_wbgt, station_name = get_nearest_wbgt_station(START_POINT[0], START_POINT[1])\n",
        "\n",
        "    # 3. RUN AI\n",
        "    pred_wbgt, trend, confidence = predict_trend(station_name, current_wbgt)\n",
        "    effective_wbgt = max(current_wbgt, pred_wbgt)\n",
        "    if NEA_HEATWAVE_ALERT: effective_wbgt = 35.0\n",
        "\n",
        "    # 4. REPORT\n",
        "    if effective_wbgt < 29: rec = \"‚úÖ Safe to Ride.\"\n",
        "    elif effective_wbgt < 31: rec = \"‚ö†Ô∏è CAUTION: Seek shade.\"\n",
        "    else: rec = \"üõë HIGH RISK: Stop.\"\n",
        "\n",
        "    print(f\"\\nüìä REPORT: {station_name}\")\n",
        "    print(f\"   Current: {current_wbgt}¬∞C | Forecast: {pred_wbgt:.1f}¬∞C\")\n",
        "\n",
        "    # 5. EXPORT KML (CLEAN LABELS)\n",
        "    kml = simplekml.Kml()\n",
        "\n",
        "    def add_route(route, color, name, description):\n",
        "        ls = kml.newlinestring(name=name)\n",
        "        coords = []\n",
        "        for u, v in zip(route[:-1], route[1:]):\n",
        "            d = graph.get_edge_data(u, v)[0]\n",
        "            if 'geometry' in d:\n",
        "                xs, ys = d['geometry'].xy\n",
        "                coords.extend(list(zip(xs, ys)))\n",
        "            else:\n",
        "                coords.append((graph.nodes[u]['x'], graph.nodes[u]['y']))\n",
        "                coords.append((graph.nodes[v]['x'], graph.nodes[v]['y']))\n",
        "        ls.coords = coords\n",
        "        ls.style.linestyle.color = color\n",
        "        ls.style.linestyle.width = 5\n",
        "        ls.description = description\n",
        "\n",
        "    # üß† FUZZY LOGIC + CLEAN LABELS\n",
        "    def check_similarity(route_a, route_b):\n",
        "        set_a = set(route_a)\n",
        "        set_b = set(route_b)\n",
        "        intersection = len(set_a.intersection(set_b))\n",
        "        union = len(set_a.union(set_b))\n",
        "        return intersection / union\n",
        "\n",
        "    sim_score = check_similarity(r1, r2)\n",
        "    print(f\"   üîç Route Similarity Score: {sim_score*100:.1f}%\")\n",
        "\n",
        "    if sim_score > 0.90:  # If >90% similar, merge them\n",
        "        print(\"   üí° Insight: Routes are effectively identical (Merged).\")\n",
        "        # MERGED LABEL\n",
        "        add_route(r2, simplekml.Color.green, \"üåü Recommended Route\",\n",
        "                  f\"<b>Smart Choice</b><br>The fastest path is also the coolest.<br>No detour needed.<br><br>Temp: {effective_wbgt:.1f}¬∞C\")\n",
        "    else:\n",
        "        print(\"   üí° Insight: A distinct cooler detour exists.\")\n",
        "        # DIVERGENT LABELS\n",
        "        add_route(r1, simplekml.Color.red, \"‚ö° Fastest Route (Exposed)\",\n",
        "                  f\"<b>Direct Path</b><br>Shortest time, but higher heat exposure.<br><br>Temp: {effective_wbgt:.1f}¬∞C\")\n",
        "        add_route(r2, simplekml.Color.green, \"üåø Cool Route (Shaded)\",\n",
        "                  f\"<b>Shaded Detour</b><br>Maximized tree canopy coverage.<br>Lower heat stress.<br><br>Temp: {effective_wbgt:.1f}¬∞C\")\n",
        "\n",
        "    # Add Shelters\n",
        "    if shelters:\n",
        "        for name, lat, lon in shelters:\n",
        "            p = kml.newpoint(name=f\"üßä {name}\", coords=[(lon, lat)])\n",
        "            p.style.iconstyle.icon.href = 'http://googleusercontent.com/maps.google.com/mapfiles/kml/shapes/snowflake_simple.png'\n",
        "\n",
        "    # 6. SAVE\n",
        "    if not os.path.exists('output'): os.makedirs('output')\n",
        "    constant_filename = \"output/latest_route.kml\"\n",
        "    kml.save(constant_filename)\n",
        "\n",
        "    print(f\"\\nüéâ SUCCESS! Download '{constant_filename}'\")\n",
        "else:\n",
        "    print(\"‚ùå Critical Error: Route Generation Failed.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}