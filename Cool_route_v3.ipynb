{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swaminaathakrishnan/Cool_Route_prototype/blob/master/Cool_route_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸš´ **CoolRide V3: AI-Driven Thermal Routing System**\n",
        "### Project Overview\n",
        "\n",
        "CoolRide is a TRL-6 prototype designed to route cyclists through thermally comfortable paths in Singapore. It utilizes real-time government weather data (NEA), satellite imagery (Vegetation), and predictive AI to mitigate Urban Heat Island (UHI) effects."
      ],
      "metadata": {
        "id": "xEQqXNM0C1M6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0EGg6-lCtkh",
        "outputId": "93348b7c-9f6a-4cf4-9b16-add64925b8d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/53.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for simplekml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "âœ… System Initialized. Ready for V3 Execution.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# ğŸ§± MODULE 1: SYSTEM INITIALIZATION\n",
        "# ==========================================\n",
        "# Objective: Install geospatial libraries and set up the environment.\n",
        "# dependencies: OSMnx (Maps), GeoPandas (Spatial Data), Scikit-Learn (AI).\n",
        "\n",
        "!pip install osmnx simplekml geopandas shapely networkx requests scikit-learn -q\n",
        "\n",
        "import osmnx as ox\n",
        "import networkx as nx\n",
        "import simplekml\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from shapely.geometry import Point, LineString, box\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "print(\"âœ… System Initialized. Ready for V3 Execution.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âš™ï¸ Module 2: Configuration & Cloud Connection\n",
        "Objective: Define the pilot zone and connect to the GitHub Data Lake. Logic: Instead of local files, we stream GeoJSON/CSV directly from the raw GitHub URLs. This allows the team to collaborate without sharing Drive folders."
      ],
      "metadata": {
        "id": "qAdgf4rmDPgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# âš™ï¸ MODULE 2: CONFIGURATION\n",
        "# ==========================================\n",
        "\n",
        "# 1. PILOT ZONE\n",
        "PLACE_NAME = \"Tampines, Singapore\"\n",
        "START_POINT = (1.3533, 103.9452) # Tampines MRT\n",
        "END_POINT = (1.3598, 103.9351)   # Tampines Eco Green\n",
        "\n",
        "# 2. GITHUB DATA LAKE (Edit these to match your repo!)\n",
        "GITHUB_USER = \"swaminaathakrishnan\"\n",
        "REPO_NAME = \"Cool_Route_prototype\"\n",
        "BASE_URL = f\"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/master/data/\"\n",
        "\n",
        "# File Links\n",
        "PCN_URL = BASE_URL + \"ParkConnectorLoop.geojson\"\n",
        "HAWKER_URL = BASE_URL + \"HawkerCentresGEOJSON.geojson\"\n",
        "TREES_URL = BASE_URL + \"trees.csv\" # The new SGTrees Data\n",
        "\n",
        "# 3. SAFETY OVERRIDE (When Govt. advisory is issued)\n",
        "NEA_HEATWAVE_ALERT = False # Set True to force extreme caution\n",
        "\n",
        "print(f\"âœ… Configuration Loaded. Connecting to Data Lake at: {GITHUB_USER}/{REPO_NAME}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTJjWFUyDNOX",
        "outputId": "f0d0c5db-7dce-4a86-fb7f-ae7df1a55a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Configuration Loaded. Connecting to Data Lake at: swaminaathakrishnan/Cool_Route_prototype\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ—ºï¸ Module 3: The Spatial Graph Engine (With SGTrees)\n",
        "\n",
        "Objective: Build the road network and overlay specific cooling features. _Upgrade: Now includes Individual Tree Analysis._\n",
        "\n",
        "Layer 1: Road Network (OSM).\n",
        "\n",
        "Layer 2: Park Connectors (PCN).\n",
        "\n",
        "Layer 3: Individual Trees (SGTrees). Logic: Roads with high tree density receive a \"Shade Bonus,\" lowering their travel cost significantly."
      ],
      "metadata": {
        "id": "15vvFycdD22Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ğŸ—ºï¸ MODULE 3: SPATIAL GRAPH ENGINE (V3.1 - LFS FIXED)\n",
        "# ==========================================\n",
        "import os\n",
        "\n",
        "def generate_cool_routes():\n",
        "    print(f\"â³ Downloading road network for {PLACE_NAME}...\")\n",
        "\n",
        "    # 1. GET GRAPH\n",
        "    G = ox.graph_from_point(START_POINT, dist=2000, network_type='bike')\n",
        "    nodes = ox.graph_to_gdfs(G, edges=False)\n",
        "    miny, maxy = nodes.y.min(), nodes.y.max()\n",
        "    minx, maxx = nodes.x.min(), nodes.x.max()\n",
        "    print(f\"   ğŸ“ Zone Limits: Lat[{miny:.4f}, {maxy:.4f}], Lon[{minx:.4f}, {maxx:.4f}]\")\n",
        "\n",
        "    # 2. LOAD PCN DATA\n",
        "    print(\"â³ Overlaying Park Connectors...\")\n",
        "    try:\n",
        "        pcn_data = gpd.read_file(PCN_URL)\n",
        "        if pcn_data.crs != \"EPSG:4326\": pcn_data = pcn_data.to_crs(\"EPSG:4326\")\n",
        "        # FIX: Updated deprecated unary_union to union_all() if available, else unary_union\n",
        "        try: pcn_union = pcn_data.geometry.union_all()\n",
        "        except: pcn_union = pcn_data.geometry.unary_union\n",
        "    except:\n",
        "        print(\"   âš ï¸ PCN Data missing. Proceeding without it.\")\n",
        "        pcn_union = None\n",
        "\n",
        "    # 3. LOAD SGTREES DATA (LFS FIX)\n",
        "    print(\"â³ Loading Tree Data (Force Download)...\")\n",
        "    trees_buffer = None\n",
        "    local_tree_file = \"trees_downloaded.csv\"\n",
        "\n",
        "    try:\n",
        "        # A. Force Download using WGET (Handles LFS redirects better than Pandas)\n",
        "        # We use the 'raw' URL structure which usually triggers the LFS blob download\n",
        "        lfs_url = f\"https://github.com/{GITHUB_USER}/{REPO_NAME}/raw/master/data/trees.csv\"\n",
        "        os.system(f\"wget -O {local_tree_file} {lfs_url}\")\n",
        "\n",
        "        # B. Read the local file\n",
        "        trees_df = pd.read_csv(local_tree_file)\n",
        "\n",
        "        # C. Check if we still got the pointer (The \"4KB trap\")\n",
        "        if len(trees_df) < 50 and \"version https\" in str(trees_df.iloc[0]):\n",
        "            raise ValueError(\"LFS Pointer detected! The 48MB file did not download.\")\n",
        "\n",
        "        # D. Normalize Columns\n",
        "        cols = [c.lower() for c in trees_df.columns]\n",
        "        trees_df.columns = cols\n",
        "        lat_col = 'latitude' if 'latitude' in cols else 'lat'\n",
        "        lng_col = 'longitude' if 'longitude' in cols else 'lng'\n",
        "\n",
        "        # E. Bounding Box Filter\n",
        "        trees_df = trees_df[\n",
        "            (trees_df[lat_col] >= miny) & (trees_df[lat_col] <= maxy) &\n",
        "            (trees_df[lng_col] >= minx) & (trees_df[lng_col] <= maxx)\n",
        "        ]\n",
        "\n",
        "        print(f\"   âœ‚ï¸ Filtered Trees: Keeping {len(trees_df)} trees for {PLACE_NAME}.\")\n",
        "\n",
        "        if len(trees_df) > 0:\n",
        "            geometry = [Point(xy) for xy in zip(trees_df[lng_col], trees_df[lat_col])]\n",
        "            trees_gdf = gpd.GeoDataFrame(trees_df, geometry=geometry, crs=\"EPSG:4326\")\n",
        "            trees_buffer = trees_gdf.geometry.buffer(0.0001).unary_union\n",
        "            print(f\"   âœ… Shade Layer Generated.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸ Tree Data Error: {e}. Skipping micro-shade analysis.\")\n",
        "\n",
        "    # 4. LOAD SHELTERS\n",
        "    shelters = []\n",
        "    try:\n",
        "        hawker_data = gpd.read_file(HAWKER_URL)\n",
        "        hawker_data = hawker_data.cx[minx:maxx, miny:maxy]\n",
        "        for _, row in hawker_data.iterrows():\n",
        "            name = row.get('Name') or row.get('NAME') or 'Shelter'\n",
        "            shelters.append((name, row.geometry.y, row.geometry.x))\n",
        "    except: pass\n",
        "\n",
        "    # 5. CALCULATE COST\n",
        "    print(\"â³ Calculating 'Micro-Shade' Scores...\")\n",
        "    for u, v, k, data in G.edges(keys=True, data=True):\n",
        "        if 'geometry' in data:\n",
        "            edge_geom = data['geometry']\n",
        "        else:\n",
        "            edge_geom = LineString([(G.nodes[u]['x'], G.nodes[u]['y']), (G.nodes[v]['x'], G.nodes[v]['y'])])\n",
        "\n",
        "        cost = data['length']\n",
        "        is_pcn = False\n",
        "        if pcn_union and edge_geom.intersects(pcn_union):\n",
        "            is_pcn = True\n",
        "            cost *= 0.5\n",
        "\n",
        "        has_shade = False\n",
        "        if trees_buffer and edge_geom.intersects(trees_buffer):\n",
        "            has_shade = True\n",
        "            cost *= 0.6\n",
        "\n",
        "        data['cool_cost'] = cost\n",
        "        data['tag'] = \"ğŸŒ¿ PCN + ğŸŒ³ Canopy\" if (is_pcn and has_shade) else \"ğŸŒ¿ PCN\" if is_pcn else \"ğŸŒ³ Shaded Road\" if has_shade else \"â˜€ï¸ Exposed\"\n",
        "\n",
        "    # 6. SOLVE\n",
        "    orig = ox.distance.nearest_nodes(G, START_POINT[1], START_POINT[0])\n",
        "    dest = ox.distance.nearest_nodes(G, END_POINT[1], END_POINT[0])\n",
        "\n",
        "    try:\n",
        "        r_fast = nx.shortest_path(G, orig, dest, weight='length')\n",
        "        r_cool = nx.shortest_path(G, orig, dest, weight='cool_cost')\n",
        "        return G, r_fast, r_cool, shelters\n",
        "    except:\n",
        "        return None, None, None, None"
      ],
      "metadata": {
        "id": "kyFS16t9D5dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§  Module 4: The Historical AI Engine (Self-Healing)\n",
        "\n",
        "Objective: Predict short-term WBGT trends using historical data. Features:\n",
        "\n",
        "Pagination Logic: Fetches huge datasets by turning API pages.\n",
        "\n",
        "Physics Clamping: Prevents unrealistic temperature predictions (>0.5Â°C swings).\n",
        "\n",
        "Self-Healing Cache: Automatically deletes bad cache files and re-learns."
      ],
      "metadata": {
        "id": "lORoECPKEX2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ğŸ§  MODULE 4: HISTORICAL AI ENGINE (V3)\n",
        "# ==========================================\n",
        "CACHE_FILE = \"coolride_weather_memory.pkl\"\n",
        "\n",
        "def get_cache():\n",
        "    if os.path.exists(CACHE_FILE):\n",
        "        try:\n",
        "            with open(CACHE_FILE, \"rb\") as f: return pickle.load(f)\n",
        "        except: return {}\n",
        "    return {}\n",
        "\n",
        "def save_cache(data):\n",
        "    with open(CACHE_FILE, \"wb\") as f: pickle.dump(data, f)\n",
        "\n",
        "def fetch_historical_data(station_name, days_back=3):\n",
        "    cache = get_cache()\n",
        "    today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    cache_key = f\"{station_name}_{today_str}\"\n",
        "\n",
        "    if cache_key in cache and len(cache[cache_key]['values']) > 20:\n",
        "        print(f\"   âš¡ Memory Hit! Loaded {len(cache[cache_key]['values'])} points.\")\n",
        "        return cache[cache_key]['timestamps'], cache[cache_key]['values']\n",
        "\n",
        "    print(f\"   ğŸ“¡ Memory Miss. Analyzing last {days_back} days...\")\n",
        "    all_timestamps, all_values = [], []\n",
        "\n",
        "    for i in range(days_back + 1):\n",
        "        target_date = (datetime.now() - timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
        "        url = \"https://api-open.data.gov.sg/v2/real-time/api/weather\"\n",
        "        params = {\"api\": \"wbgt\", \"date\": target_date}\n",
        "\n",
        "        # PAGINATION LOOP\n",
        "        while True:\n",
        "            try:\n",
        "                resp = requests.get(url, params=params, timeout=5)\n",
        "                if resp.status_code != 200: break\n",
        "                data = resp.json()\n",
        "                if 'data' not in data: break\n",
        "\n",
        "                for rec in data['data'].get('records', []):\n",
        "                    dt = datetime.fromisoformat(rec['datetime'])\n",
        "                    for r in rec['item']['readings']:\n",
        "                        if r.get('station', {}).get('name') == station_name:\n",
        "                            val = float(r.get('wbgt') or r.get('value'))\n",
        "                            mins = dt.hour * 60 + dt.minute\n",
        "                            now_mins = datetime.now().hour * 60 + datetime.now().minute\n",
        "                            if abs(mins - now_mins) < 240: # 4 hour window\n",
        "                                all_timestamps.append(mins)\n",
        "                                all_values.append(val)\n",
        "\n",
        "                token = data['data'].get('paginationToken')\n",
        "                if token: params['paginationToken'] = token\n",
        "                else: break\n",
        "            except: break\n",
        "\n",
        "    if len(all_values) > 20:\n",
        "        cache[cache_key] = {'timestamps': all_timestamps, 'values': all_values}\n",
        "        save_cache(cache)\n",
        "        print(f\"   ğŸ’¾ Learned & Saved {len(all_values)} thermal patterns.\")\n",
        "\n",
        "    return all_timestamps, all_values\n",
        "\n",
        "def predict_trend(station_name, current_wbgt):\n",
        "    timestamps, values = fetch_historical_data(station_name)\n",
        "    if len(values) < 10: return current_wbgt, \"Stable â–\", \"Low Data\"\n",
        "\n",
        "    # Linear Regression\n",
        "    model = LinearRegression()\n",
        "    model.fit(np.array(timestamps).reshape(-1, 1), np.array(values))\n",
        "\n",
        "    # Forecast\n",
        "    now = datetime.now()\n",
        "    fut_min = now.hour * 60 + now.minute + 15\n",
        "    raw_pred = model.predict([[fut_min]])[0]\n",
        "\n",
        "    # Physics Clamp\n",
        "    delta = raw_pred - current_wbgt\n",
        "    if abs(delta) > 0.5:\n",
        "        final_pred = current_wbgt + (0.5 if delta > 0 else -0.5)\n",
        "        note = \"(Physics Clamped)\"\n",
        "    else:\n",
        "        final_pred = raw_pred\n",
        "        note = \"\"\n",
        "\n",
        "    trend = \"Rising ğŸ“ˆ\" if final_pred > current_wbgt + 0.1 else \"Falling ğŸ“‰\" if final_pred < current_wbgt - 0.1 else \"Stable â–\"\n",
        "    return final_pred, trend, f\"High {note}\""
      ],
      "metadata": {
        "id": "MqM53NLEEZ97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸš€ Module 5: Execution & Safe-Pace Recommendations\n",
        "\n",
        "Objective: Synthesize map, weather, and AI data into a KML route. Upgrade:\n",
        "\n",
        "* Govt Override: Checks NEA_HEATWAVE_ALERT.\n",
        "* Safe Pacing: Suggests specific ride speeds and hydration intervals based on WBGT (ISO 7243 standards)."
      ],
      "metadata": {
        "id": "owRqKP4MEvtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ğŸš€ MODULE 5: EXECUTION ENGINE (V3.9 - FINAL LABELS)\n",
        "# ==========================================\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import simplekml\n",
        "\n",
        "print(\"ğŸš€ STARTING COOLRIDE ENGINE (WITH ACTIVE AI)...\")\n",
        "\n",
        "# --- HELPER: DYNAMIC SENSOR FINDER (FULL V2 LOGIC) ---\n",
        "def get_nearest_wbgt_station(lat, lon):\n",
        "    print(\"â³ Connecting to NEA Official WBGT Sensor Network...\")\n",
        "    url = \"https://api-open.data.gov.sg/v2/real-time/api/weather\"\n",
        "    try:\n",
        "        resp = requests.get(url, params={\"api\": \"wbgt\"}, timeout=10)\n",
        "        data = resp.json()\n",
        "        readings = data['data']['records'][0]['item'].get('readings', [])\n",
        "\n",
        "        closest_station = \"Unknown\"\n",
        "        min_dist = float('inf')\n",
        "        current_val = None\n",
        "\n",
        "        for r in readings:\n",
        "            try:\n",
        "                loc = {}\n",
        "                s_name = \"Unknown\"\n",
        "                if 'location' in r: loc = r['location']\n",
        "                elif 'station' in r and 'location' in r['station']: loc = r['station']['location']\n",
        "                if 'station' in r: s_name = r['station'].get('name', 'Unknown')\n",
        "                s_lat = float(loc.get('latitude', 0))\n",
        "                s_lon = float(loc.get('longitude', loc.get('longtitude', 0)))\n",
        "                if s_lat == 0 or s_lon == 0: continue\n",
        "\n",
        "                val = r.get('wbgt') or r.get('value')\n",
        "                if val is None: continue\n",
        "                val = float(val)\n",
        "                dist = math.sqrt((lat - s_lat)**2 + (lon - s_lon)**2)\n",
        "\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    closest_station = s_name\n",
        "                    current_val = val\n",
        "            except: continue\n",
        "\n",
        "        if current_val is None: return 30.0, \"System Fallback\"\n",
        "        print(f\"   ğŸ“ Nearest Sensor: {closest_station} (Dist: {min_dist*111:.2f} km)\")\n",
        "        return current_val, closest_station\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸ WBGT Sensor Fail: {e}. Using Default Safety Value.\")\n",
        "        return 30.0, \"System Fallback\"\n",
        "\n",
        "# 1. GENERATE ROUTES\n",
        "graph, r1, r2, shelters = generate_cool_routes()\n",
        "\n",
        "if graph:\n",
        "    # 2. GET WEATHER\n",
        "    current_wbgt, station_name = get_nearest_wbgt_station(START_POINT[0], START_POINT[1])\n",
        "\n",
        "    # 3. RUN AI\n",
        "    pred_wbgt, trend, confidence = predict_trend(station_name, current_wbgt)\n",
        "    effective_wbgt = max(current_wbgt, pred_wbgt)\n",
        "    if NEA_HEATWAVE_ALERT: effective_wbgt = 35.0\n",
        "\n",
        "    # 4. REPORT\n",
        "    if effective_wbgt < 29: rec = \"âœ… Safe to Ride.\"\n",
        "    elif effective_wbgt < 31: rec = \"âš ï¸ CAUTION: Seek shade.\"\n",
        "    else: rec = \"ğŸ›‘ HIGH RISK: Stop.\"\n",
        "\n",
        "    print(f\"\\nğŸ“Š REPORT: {station_name}\")\n",
        "    print(f\"   Current: {current_wbgt}Â°C | Forecast: {pred_wbgt:.1f}Â°C\")\n",
        "\n",
        "    # 5. EXPORT KML (CLEAN LABELS)\n",
        "    kml = simplekml.Kml()\n",
        "\n",
        "    def add_route(route, color, name, description):\n",
        "        ls = kml.newlinestring(name=name)\n",
        "        coords = []\n",
        "        for u, v in zip(route[:-1], route[1:]):\n",
        "            d = graph.get_edge_data(u, v)[0]\n",
        "            if 'geometry' in d:\n",
        "                xs, ys = d['geometry'].xy\n",
        "                coords.extend(list(zip(xs, ys)))\n",
        "            else:\n",
        "                coords.append((graph.nodes[u]['x'], graph.nodes[u]['y']))\n",
        "                coords.append((graph.nodes[v]['x'], graph.nodes[v]['y']))\n",
        "        ls.coords = coords\n",
        "        ls.style.linestyle.color = color\n",
        "        ls.style.linestyle.width = 5\n",
        "        ls.description = description\n",
        "\n",
        "    # ğŸ§  FUZZY LOGIC + CLEAN LABELS\n",
        "    def check_similarity(route_a, route_b):\n",
        "        set_a = set(route_a)\n",
        "        set_b = set(route_b)\n",
        "        intersection = len(set_a.intersection(set_b))\n",
        "        union = len(set_a.union(set_b))\n",
        "        return intersection / union\n",
        "\n",
        "    sim_score = check_similarity(r1, r2)\n",
        "    print(f\"   ğŸ” Route Similarity Score: {sim_score*100:.1f}%\")\n",
        "\n",
        "    if sim_score > 0.90:  # If >90% similar, merge them\n",
        "        print(\"   ğŸ’¡ Insight: Routes are effectively identical (Merged).\")\n",
        "        # MERGED LABEL\n",
        "        add_route(r2, simplekml.Color.green, \"ğŸŒŸ Recommended Route\",\n",
        "                  f\"<b>Smart Choice</b><br>The fastest path is also the coolest.<br>No detour needed.<br><br>Temp: {effective_wbgt:.1f}Â°C\")\n",
        "    else:\n",
        "        print(\"   ğŸ’¡ Insight: A distinct cooler detour exists.\")\n",
        "        # DIVERGENT LABELS\n",
        "        add_route(r1, simplekml.Color.red, \"âš¡ Fastest Route (Exposed)\",\n",
        "                  f\"<b>Direct Path</b><br>Shortest time, but higher heat exposure.<br><br>Temp: {effective_wbgt:.1f}Â°C\")\n",
        "        add_route(r2, simplekml.Color.green, \"ğŸŒ¿ Cool Route (Shaded)\",\n",
        "                  f\"<b>Shaded Detour</b><br>Maximized tree canopy coverage.<br>Lower heat stress.<br><br>Temp: {effective_wbgt:.1f}Â°C\")\n",
        "\n",
        "    # Add Shelters\n",
        "    if shelters:\n",
        "        for name, lat, lon in shelters:\n",
        "            p = kml.newpoint(name=f\"ğŸ§Š {name}\", coords=[(lon, lat)])\n",
        "            p.style.iconstyle.icon.href = 'http://googleusercontent.com/maps.google.com/mapfiles/kml/shapes/snowflake_simple.png'\n",
        "\n",
        "    # 6. SAVE\n",
        "    if not os.path.exists('output'): os.makedirs('output')\n",
        "    constant_filename = \"output/latest_route.kml\"\n",
        "    kml.save(constant_filename)\n",
        "\n",
        "    print(f\"\\nğŸ‰ SUCCESS! Download '{constant_filename}'\")\n",
        "else:\n",
        "    print(\"âŒ Critical Error: Route Generation Failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbhsl3iKExZF",
        "outputId": "3dfac1f6-fc53-432d-a82b-586ce40a6660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ STARTING COOLRIDE ENGINE (WITH ACTIVE AI)...\n",
            "â³ Downloading road network for Tampines, Singapore...\n",
            "   ğŸ“ Zone Limits: Lat[1.3353, 1.3713], Lon[103.9273, 103.9632]\n",
            "â³ Overlaying Park Connectors...\n",
            "â³ Loading Tree Data (Force Download)...\n",
            "   âœ‚ï¸ Filtered Trees: Keeping 29766 trees for Tampines, Singapore.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2707566625.py:63: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  trees_buffer = trees_gdf.geometry.buffer(0.0001).unary_union\n",
            "/tmp/ipython-input-2707566625.py:63: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
            "  trees_buffer = trees_gdf.geometry.buffer(0.0001).unary_union\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ… Shade Layer Generated.\n",
            "â³ Calculating 'Micro-Shade' Scores...\n",
            "â³ Connecting to NEA Official WBGT Sensor Network...\n",
            "   ğŸ“ Nearest Sensor: Bedok North Street 2 (Dist: 3.12 km)\n",
            "   âš¡ Memory Hit! Loaded 128 points.\n",
            "\n",
            "ğŸ“Š REPORT: Bedok North Street 2\n",
            "   Current: 27.3Â°C | Forecast: 26.8Â°C\n",
            "   ğŸ” Route Similarity Score: 93.1%\n",
            "   ğŸ’¡ Insight: Routes are effectively identical (Merged).\n",
            "\n",
            "ğŸ‰ SUCCESS! Download 'output/latest_route.kml'\n"
          ]
        }
      ]
    }
  ]
}